{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CART:    \n",
    "    def __init__(self, features_rate, min_samples_leaf, max_depth):\n",
    "        self.features_rate = features_rate\n",
    "        self.tree_map = {}\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        if (max_depth == None):\n",
    "            self.max_depth = 100000\n",
    "        else:\n",
    "            self.max_depth = max_depth\n",
    "\n",
    "    def gen_tree(self, element_numbers, vertex_num, mean, now_depth, mse_value):\n",
    "         \n",
    "        if (now_depth == self.max_depth):  \n",
    "            self.tree_map[str(vertex_num)] = [[None, None], [1], [mean], [None, None]]\n",
    "            return 0\n",
    "        \n",
    "        min_mse = mse_value\n",
    "\n",
    "        pos_num_split = np.nan\n",
    "        value_split = np.nan\n",
    "        \n",
    "        left = []\n",
    "        right = []\n",
    "        \n",
    "        cou_elements = len(element_numbers)\n",
    "        \n",
    "        best_left_square_sum = np.nan\n",
    "        best_left_sum = np.nan\n",
    "        best_right_square_sum = np.nan\n",
    "        best_right_sum = np.nan\n",
    "        \n",
    "        x = self.x[element_numbers]\n",
    "        y = self.y[element_numbers]\n",
    "\n",
    "        for feature_num in range(self.features_cou_analize):\n",
    "\n",
    "            sort_ind = x[:,feature_num].argsort()\n",
    "            new_x = x[:,feature_num][sort_ind]\n",
    "            new_y = y[sort_ind]\n",
    "            \n",
    "            left_cou = 0\n",
    "            right_cou = cou_elements\n",
    "            \n",
    "            del_num = 0\n",
    "            right_square_sum = mse_value + mean * mean * cou_elements * 1.0\n",
    "            right_sum = mean * cou_elements * 1.0\n",
    "            left_square_sum = 0.0\n",
    "            left_sum = 0.0\n",
    "            feature_value_split = np.nan\n",
    "            for i, feature_value in enumerate(new_x):\n",
    "                \n",
    "                if (feature_value_split == feature_value):\n",
    "                    continue\n",
    "                    \n",
    "                if (np.isnan(feature_value_split)):\n",
    "                    feature_value_split = feature_value\n",
    "                else:\n",
    "                    feature_value_split = 0.5 * (feature_value_split + feature_value)\n",
    "                    \n",
    "                while (1):\n",
    "                    if (new_x[del_num] < feature_value_split):\n",
    "                        y_val = new_y[del_num]\n",
    "                        del_num += 1\n",
    "                        left_cou += 1\n",
    "                        right_cou -= 1\n",
    "                        \n",
    "                        left_square_sum += y_val * y_val\n",
    "                        left_sum += y_val\n",
    "                        \n",
    "                        right_square_sum -= y_val * y_val\n",
    "                        right_sum -= y_val\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                if (left_cou < self.min_samples_leaf):\n",
    "                    continue\n",
    "                elif (right_cou < self.min_samples_leaf):\n",
    "                    break\n",
    "                \n",
    "                now_left_mse = left_square_sum - left_sum * left_sum * 1.0/ left_cou\n",
    "                now_right_mse = right_square_sum - right_sum * right_sum * 1.0 / right_cou\n",
    "                \n",
    "                if (now_left_mse + now_right_mse < min_mse):\n",
    "                    min_mse = now_left_mse + now_right_mse\n",
    "                    pos_num_split = feature_num\n",
    "                    value_split = feature_value_split\n",
    "                    \n",
    "                    best_left_square_sum = left_square_sum\n",
    "                    best_left_sum = left_sum\n",
    "                    \n",
    "                    best_right_square_sum = right_square_sum\n",
    "                    best_right_sum = right_sum\n",
    "                    \n",
    "        if (np.isnan(value_split)):\n",
    "            self.tree_map[str(vertex_num)]= [[None, None], [1], [mean], [None, None]]\n",
    "            return 0\n",
    "        \n",
    "        self.tree_map[str(vertex_num)] = [[self.feature_order[pos_num_split], value_split], [0], [mean], [vertex_num*2 + 1, vertex_num*2 + 2]]\n",
    "        \n",
    "        \n",
    "        left_class = []\n",
    "        right_class = []\n",
    "        \n",
    "        for pos in element_numbers:\n",
    "            if (self.x[pos][pos_num_split] < value_split):\n",
    "                left.append(pos)\n",
    "            else:\n",
    "                right.append(pos)\n",
    "\n",
    "        left_mse = best_left_square_sum - (best_left_sum ** 2.0) / len(left)\n",
    "        right_mse = best_right_square_sum - (best_right_sum ** 2.0) / len(right)\n",
    "        \n",
    "        self.feature_contribution[self.feature_order[pos_num_split]] += (mse_value - left_mse - right_mse)\n",
    "        \n",
    "        self.gen_tree(left, vertex_num*2 + 1, best_left_sum * 1.0 / len(left), now_depth + 1, left_mse)\n",
    "        self.gen_tree(right, vertex_num*2 + 2, best_right_sum *1.0/ len(right), now_depth + 1, right_mse)\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.tree_map = {}\n",
    "        \n",
    "        x = np.asarray(x, dtype = np.float)\n",
    "        features_cou = (x.shape)[1]\n",
    "        self.feature_order = np.sort(np.random.choice((x.shape)[1], int((x.shape)[1] * (self.features_rate)), replace=False))\n",
    "        \n",
    "        self.features_cou_analize = int((x.shape)[1] * (self.features_rate))\n",
    "        self.cou_samples = len(x)\n",
    "        \n",
    "        self.feature_contribution = np.zeros(features_cou)\n",
    "        \n",
    "        for i in reversed(range(features_cou)):\n",
    "            if (i not in self.feature_order):\n",
    "                x = np.delete(x, i, 1)\n",
    "\n",
    "        self.x = x\n",
    "        self.y = np.asarray(y, dtype = np.float)\n",
    "        y_pred = np.tile(np.sum(y) * 1.0 / len(y), len(y))\n",
    "        \n",
    "        self.gen_tree(np.arange(self.cou_samples), 0, np.sum(y) * 1.0 / len(y), 0, np.sum((y_pred - self.y) ** 2.0))\n",
    "        \n",
    "        return self.tree_map\n",
    "\n",
    "    def predict(self, data):\n",
    "        y_pred = []\n",
    "        for sample in data:\n",
    "            now_vertex = 0\n",
    "            while (1):\n",
    "                if (self.tree_map[str(now_vertex)][1][0] == 1):\n",
    "                    break\n",
    "                if (sample[self.tree_map[str(now_vertex)][0][0]] >= self.tree_map[str(now_vertex)][0][1]):\n",
    "                    now_vertex = self.tree_map[str(now_vertex)][3][1]\n",
    "                else:\n",
    "                    now_vertex = self.tree_map[str(now_vertex)][3][0]\n",
    "            y_pred.append(self.tree_map[str(now_vertex)][2][0])\n",
    "        return y_pred\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"spam.train.txt\", \"r\")\n",
    "y_true = []\n",
    "data = []\n",
    "for line in f:\n",
    "    line = line[:len(line) - 1]\n",
    "    arr = line.split(' ')\n",
    "    y_true.append(arr[0])\n",
    "    del arr[0]\n",
    "    data.append(arr)\n",
    "x = np.asarray(data, dtype = np.float)\n",
    "y = np.asarray(y_true, dtype = np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"spam.test.txt\", \"r\")\n",
    "test_data = []\n",
    "test_y = []\n",
    "for line in f:\n",
    "    line = line[:len(line) - 1]\n",
    "    arr = line.split(' ')\n",
    "    test_y.append(arr[0])\n",
    "    del arr[0]\n",
    "    test_data.append(arr)\n",
    "    \n",
    "test_x = np.asarray(test_data, dtype = np.float)\n",
    "test_y = np.asarray(test_y, dtype = np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class modify_gb:\n",
    "    \n",
    "    def __init__(self, n_estimators, features_rate, cou_samples, min_samples_split, learning_rate, max_depth, loss, regularizator_value):\n",
    "        self.regularizator_value = regularizator_value\n",
    "        self.number_elements_in_subsample = cou_samples / n_estimators\n",
    "        self.n_estimators = n_estimators\n",
    "        self.features_rate = features_rate\n",
    "        self.cou_samples = cou_samples\n",
    "        self.loss = loss\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.shrinkage_value = learning_rate\n",
    "        if (max_depth == None):\n",
    "            self.max_depth = 10000\n",
    "        else:\n",
    "            self.max_depth = max_depth\n",
    "    \n",
    "    def get_predict_for_sample_and_one_tree(self, sample, tree_map):\n",
    "        now_vertex = 0\n",
    "        while (1):\n",
    "            if (tree_map[str(now_vertex)][1][0] == 1):\n",
    "                break\n",
    "            if (sample[tree_map[str(now_vertex)][0][0]] >= tree_map[str(now_vertex)][0][1]):\n",
    "                now_vertex = tree_map[str(now_vertex)][3][1]\n",
    "            else:\n",
    "                now_vertex = tree_map[str(now_vertex)][3][0]\n",
    "        return tree_map[str(now_vertex)][2][0]\n",
    "    \n",
    "    def get_predict_for_sample(self, sample):\n",
    "        answer = 0.0\n",
    "        for i in range(len(self.trees_list)):\n",
    "            answer += self.shrinkage_value * self.get_predict_for_sample_and_one_tree(sample, self.trees_list[i][1])\n",
    "        return answer\n",
    "    \n",
    "    def update_grad_for_l2(self, x, tree_map):\n",
    "        for i, sample in enumerate(x):\n",
    "            self.now_grad[i] -= 2.0 * self.get_predict_for_sample_and_one_tree(sample, tree_map) * self.shrinkage_value\n",
    "            \n",
    "    def update_grad_for_l1(self, x, tree_map):\n",
    "        for i, sample in enumerate(x):\n",
    "            pred_for_sample = self.get_predict_for_sample_and_one_tree(sample, tree_map) * self.shrinkage_value\n",
    "            self.y_balance[i] -= pred_for_sample\n",
    "            if (self.y_balance[i] == 0.0):\n",
    "                self.now_grad[i] = 0.00000001\n",
    "            elif (self.y_balance[i] > 0.0):\n",
    "                self.now_grad[i] = 1.0\n",
    "            elif (self.y_balance[i] < 0.0):\n",
    "                self.now_grad[i] = -1.0\n",
    "        \n",
    "        \n",
    "    def predict_regression(self, x):\n",
    "        y_pred = np.zeros(len(x))\n",
    "        for i, sample in enumerate(x):\n",
    "            y_pred[i] = self.get_predict_for_sample(sample)\n",
    "        return y_pred\n",
    "    \n",
    "    def predict_regression_after_select(self, x):\n",
    "        x = x[:, self.good_features]\n",
    "        y_pred = np.zeros(len(x))\n",
    "        for i, sample in enumerate(x):\n",
    "            y_pred[i] = self.get_predict_for_sample(sample)\n",
    "        return y_pred\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.pos_arr = np.arange(self.cou_samples)\n",
    "        self.now_grad = np.array(y, dtype = np.float)\n",
    "        self.trees_list = []\n",
    "        self.y_balance = np.array(y, dtype = np.float)\n",
    "        \n",
    "        cart = CART(self.features_rate, self.min_samples_split, self.max_depth)\n",
    "        \n",
    "        self.feature_contribution = np.zeros((x.shape)[1])\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            np.random.shuffle(self.pos_arr)\n",
    "            index = self.pos_arr[:self.cou_samples / 2]\n",
    "            now_x = x[index]\n",
    "            now_y = self.now_grad[index]\n",
    "            \n",
    "            cart.fit(now_x, now_y)\n",
    "            if (i == 0 and self.loss == 'l2'):\n",
    "                self.now_grad *= 2.0\n",
    "            elif (i == 0 and self.loss == 'l1'):\n",
    "                self.now_grad = np.zeros(len(self.now_grad))\n",
    "                \n",
    "            self.feature_contribution += cart.feature_contribution\n",
    "            \n",
    "            self.trees_list.append([self.shrinkage_value, cart.tree_map])\n",
    "            \n",
    "            if (self.loss == 'l2'):\n",
    "                self.update_grad_for_l2(x, cart.tree_map)\n",
    "            elif (self.loss == 'l1'):\n",
    "                self.update_grad_for_l1(x, cart.tree_map)\n",
    "                \n",
    "        return self.trees_list\n",
    "    \n",
    "    def feature_selection_and_fit(self, x, y):\n",
    "        print x.shape\n",
    "        self.fit(x, y)\n",
    "        old_trees_list = self.trees_list\n",
    "        old_contrib = self.feature_contribution\n",
    "        feature_probability = self.feature_contribution / np.sum(self.feature_contribution)\n",
    "        print feature_probability\n",
    "        #self.regularizator_value = (sorted(feature_probability))[int(x.shape[1] * 0.2)]\n",
    "        self.good_features = []\n",
    "        cou_features = x.shape[1]\n",
    "        for i in reversed(range(cou_features)):\n",
    "            if (feature_probability[i] < self.regularizator_value):\n",
    "                x = np.delete(x, i, axis = 1)\n",
    "            else:\n",
    "                self.good_features.append(i)\n",
    "        self.good_features = sorted(self.good_features)\n",
    "        self.trees_list = []\n",
    "        self.fit(x, y)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add noise features and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature1 = np.random.binomial(10000, 0.9, len(y_true))\n",
    "feature2 = np.random.binomial(1000, 0.8, len(y_true))\n",
    "feature3 = np.random.normal(0, 10, len(y_true))\n",
    "feature4 = np.random.normal(21, 15, len(y_true))\n",
    "feature5 = np.random.geometric(p=0.1, size=len(y_true))\n",
    "feature6 = np.random.chisquare(15,len(y_true))\n",
    "feature7 = np.random.uniform(-10,10,len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.insert(x, x.shape[1], feature1, axis = 1)\n",
    "x = np.insert(x, x.shape[1], feature2, axis = 1)\n",
    "x = np.insert(x, x.shape[1], feature3, axis = 1)\n",
    "x = np.insert(x, x.shape[1], feature4, axis = 1)\n",
    "x = np.insert(x, x.shape[1], feature5, axis = 1)\n",
    "x= np.insert(x, x.shape[1], feature6, axis = 1)\n",
    "x = np.insert(x, x.shape[1], feature7, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature1 = np.random.binomial(10000, 0.9, len(test_y))\n",
    "feature2 = np.random.binomial(1000, 0.8, len(test_y))\n",
    "feature3 = np.random.normal(0, 10, len(test_y))\n",
    "feature4 = np.random.normal(21, 15, len(test_y))\n",
    "feature5 = np.random.geometric(p=0.1, size=len(test_y))\n",
    "feature6 = np.random.chisquare(15,len(test_y))\n",
    "feature7 = np.random.uniform(-10,10,len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = np.insert(test_x, test_x.shape[1], feature1, axis = 1)\n",
    "test_x = np.insert(test_x, test_x.shape[1], feature2, axis = 1)\n",
    "test_x = np.insert(test_x, test_x.shape[1], feature3, axis = 1)\n",
    "test_x = np.insert(test_x, test_x.shape[1], feature4, axis = 1)\n",
    "test_x = np.insert(test_x, test_x.shape[1], feature5, axis = 1)\n",
    "test_x = np.insert(test_x, test_x.shape[1], feature6, axis = 1)\n",
    "test_x = np.insert(test_x, test_x.shape[1], feature7, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators': 100, 'features_rate': 1.0, 'cou_samples': len(data), 'min_samples_split': 10,\n",
    "                    'learning_rate' : 0.03, 'max_depth' : 4, 'loss' : 'l2', 'regularizator_value' : 0.0008}\n",
    "clf_without_select = modify_gb(**params)\n",
    "clf_with_select = modify_gb(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7093, 109)\n",
      "[  6.40058112e-04   2.97237875e-04   6.17154341e-04   1.67355370e-03\n",
      "   2.32327605e-02   1.40927175e-03   3.06870810e-03   4.40766503e-04\n",
      "   2.99764420e-02   3.78382912e-02   3.79763339e-02   4.00784256e-03\n",
      "   3.03782891e-03   3.45312017e-03   1.15385515e-02   1.23393836e-02\n",
      "   2.35350744e-02   2.35920573e-02   1.51186268e-03   2.90979334e-03\n",
      "   1.91159272e-03   6.63684356e-04   1.89067040e-03   8.77411142e-04\n",
      "   1.75919682e-03   3.44409863e-04   9.20213249e-04   6.10890668e-04\n",
      "   1.08310442e-03   6.51499105e-03   1.58615379e-03   7.78656366e-03\n",
      "   6.12712060e-03   4.56051610e-03   0.00000000e+00   2.72741632e-02\n",
      "   9.09753613e-05   3.12898249e-03   7.23020827e-03   1.36462154e-03\n",
      "   5.11795785e-04   1.31400022e-02   4.91929552e-04   6.25580443e-03\n",
      "   3.64579304e-05   2.79846844e-04   8.63338273e-04   5.45328937e-03\n",
      "   3.13009987e-01   2.44096409e-02   1.41217841e-03   2.89374392e-03\n",
      "   1.03701534e-02   2.94152809e-02   1.03199285e-03   2.21992976e-03\n",
      "   2.41599829e-02   0.00000000e+00   0.00000000e+00   7.10357673e-04\n",
      "   0.00000000e+00   1.25149357e-03   1.16602399e-03   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   6.18346302e-02   3.88466441e-02\n",
      "   9.77403846e-04   9.69325290e-03   3.16908717e-03   5.14681480e-03\n",
      "   5.70119770e-03   7.24260112e-04   2.67455501e-04   1.70996595e-03\n",
      "   5.52225912e-04   5.39138103e-04   1.68903462e-04   3.13533061e-03\n",
      "   6.34739817e-04   0.00000000e+00   9.88049376e-04   1.96530283e-03\n",
      "   1.21843471e-03   0.00000000e+00   1.14050184e-03   2.29324522e-04\n",
      "   4.28520540e-04   4.87037635e-05   0.00000000e+00   7.99491371e-04\n",
      "   2.17634596e-04   0.00000000e+00   5.13257272e-04   3.62748157e-04\n",
      "   8.74995880e-04   1.18440150e-01   1.63895838e-04   5.71227167e-04\n",
      "   1.67980441e-04   0.00000000e+00   1.75027762e-04   2.70906503e-04\n",
      "   4.18005988e-04]\n",
      "(7093, 61)\n",
      "0.186087076406\n",
      "[  3.75175436e+01   7.72076955e+02   4.00566720e+01   1.74335646e+01\n",
      "   8.71708391e+02   7.51455707e+02   1.19353946e+03   1.16323679e+02\n",
      "   7.32046220e+01   9.26423311e+01   2.45330597e+02   5.02650968e+02\n",
      "   6.52429168e+02   7.43930205e+02   7.77725279e+01   9.14317131e+01\n",
      "   1.22692064e+01   1.88143313e+01   5.60152250e+01   5.01870472e+01\n",
      "   1.54528672e+01   2.41444778e+00   2.10928155e+02   5.50783505e+01\n",
      "   2.26595298e+02   2.74616907e+02   9.70899489e+01   8.15993588e+02\n",
      "   5.88894797e+01   2.24789196e+02   5.96300607e+01   2.47628105e+02\n",
      "   1.85004953e+02   1.87083863e+01   1.51704184e+02   8.34592900e+03\n",
      "   6.98419472e+02   1.12445256e+02   5.72247983e+01   3.93675965e+02\n",
      "   8.38480744e+02   2.70000474e+01   6.68111206e+01   8.93152622e+02\n",
      "   6.78119746e+00   1.06814110e+01   1.78228727e+03   1.12987323e+03\n",
      "   5.91961498e+01   2.55651178e+02   4.12628115e+01   1.78934595e+02\n",
      "   1.87354431e+02   8.99432983e+01   9.41829584e+01   2.81758566e+01\n",
      "   3.33228778e+01   2.43912633e+01   2.43564475e+01   6.81453985e+01\n",
      "   3.34243987e+03]\n",
      "[101, 100, 90, 88, 87, 86, 83, 79, 76, 75, 74, 73, 72, 71, 70, 62, 61, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 43, 41, 39, 38, 37, 35, 33, 32, 31, 30, 29, 28, 26, 24, 23, 22, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 6, 5, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "clf_with_select.feature_selection_and_fit(x, y)\n",
    "y_pred = clf_with_select.predict_regression_after_select(test_x)\n",
    "print sk.metrics.mean_squared_error(y_pred, test_y)\n",
    "print clf_with_select.feature_contribution\n",
    "print clf_with_select.good_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0659536577396\n",
      "[  1.33834380e+01   1.74518572e+01   8.45495410e+00   4.15463415e+01\n",
      "   7.00860450e+02   5.90964148e+01   6.28780343e+01   9.21775643e+00\n",
      "   9.31657215e+02   8.69705396e+02   1.08714901e+03   1.59880212e+02\n",
      "   8.29780438e+01   1.13266821e+02   2.61762842e+02   4.24994520e+02\n",
      "   6.79385216e+02   7.05613168e+02   2.87277974e+01   5.71683573e+01\n",
      "   3.25725512e+01   1.22308236e+01   2.48334469e+01   3.73824897e+01\n",
      "   5.34587804e+01   1.56469932e+01   3.83902958e+00   2.15181063e+01\n",
      "   9.54630667e+00   2.53237991e+02   7.23120878e+01   1.52865259e+02\n",
      "   3.17523955e+02   7.20587082e+01   0.00000000e+00   8.32734796e+02\n",
      "   3.94818545e+00   9.05906029e+01   2.28506208e+02   1.35214681e+01\n",
      "   8.43782555e+00   4.37433738e+02   6.79138640e+01   8.95983814e+01\n",
      "   4.24517631e+00   1.56756382e+01   3.04817165e+00   1.40797682e+02\n",
      "   8.42440143e+03   1.16053184e+03   1.12778831e+02   5.42175302e+01\n",
      "   2.49278915e+02   7.72306229e+02   6.24464129e+01   8.86121034e+01\n",
      "   4.88913494e+02   0.00000000e+00   3.76121753e+00   3.39885360e+01\n",
      "   0.00000000e+00   4.67396773e+01   1.63377480e+01   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.69637145e+03   1.12302959e+03\n",
      "   4.14701902e+01   2.56318345e+02   3.64581927e+01   1.55296273e+02\n",
      "   1.72581424e+02   6.02229773e+00   1.89771786e+01   2.33138101e+01\n",
      "   1.71522655e+01   2.37885007e+00   3.20856323e+00   7.72920015e+01\n",
      "   9.75255540e+00   9.57543201e+00   4.87516172e+00   6.39530401e+01\n",
      "   4.67685348e+01   0.00000000e+00   4.39910735e+01   9.80159741e+00\n",
      "   0.00000000e+00   6.90085985e+00   5.13242900e+00   1.75536655e+01\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   4.35612721e+01   3.05837538e+03   1.73255729e+00   5.44768808e-01\n",
      "   2.37356905e+00   3.73095626e+00   1.48776586e+00   1.80470393e+00\n",
      "   3.46178720e+00]\n"
     ]
    }
   ],
   "source": [
    "clf_without_select.fit(x, y)\n",
    "y_pred = clf_without_select.predict_regression(test_x)\n",
    "print sk.metrics.mean_squared_error(y_pred, test_y)\n",
    "print clf_without_select.feature_contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10056, 109)\n"
     ]
    }
   ],
   "source": [
    "print test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for keyword argument 'handles'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-67d878452dba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mwithout_select\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse_without_select\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"without select\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mwithout_select_bound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse_without_select\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"without select bound\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwithout_select\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwithout_select_bound\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cou_estimators'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/pymodules/python2.7/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mlegend\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3379\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3380\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3381\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3382\u001b[0m     \u001b[0mdraw_if_interactive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3383\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/pymodules/python2.7/matplotlib/axes.pyc\u001b[0m in \u001b[0;36mlegend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4776\u001b[0m         \u001b[1;31m# handles = cbook.flatten(handles)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4778\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlegend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4779\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got multiple values for keyword argument 'handles'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFwCAYAAABzZegiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERERERERERERERERERERERERET6pv8HjCHo2ayyhNwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d88b80cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = test_y.copy()\n",
    "y1 = test_y.copy()\n",
    "estimators_list = np.linspace(1, 100, 100)\n",
    "mse_select = []\n",
    "mse_without_select = []\n",
    "cou_samples = len(test_y)\n",
    "clf_with_select.good_features = sorted(clf_with_select.good_features)\n",
    "select_x = test_x[:, clf_with_select.good_features]\n",
    "y = np.array(y, dtype = np.float)\n",
    "y1 = np.array(y1, dtype = np.float)\n",
    "for i in range(0, 100):\n",
    "    for j, sample in enumerate(select_x):\n",
    "        y[j] -= clf_with_select.get_predict_for_sample_and_one_tree(sample, clf_with_select.trees_list[i][1]) * clf_with_select.shrinkage_value\n",
    "    for j, sample in enumerate(test_x):\n",
    "        y1[j] -= clf_without_select.get_predict_for_sample_and_one_tree(sample, clf_without_select.trees_list[i][1]) * clf_without_select.shrinkage_value\n",
    "    if (i + 1 in estimators_list):\n",
    "        mse_select.append(np.sum(y ** 2.0) * 1.0 / cou_samples)\n",
    "        mse_without_select.append(np.sum(y1 ** 2.0) * 1.0 / cou_samples)\n",
    "    \n",
    "        \n",
    "estimators_list = np.asarray(estimators_list, dtype = np.float)\n",
    "plt.figure(figsize = (8, 6), dpi = 80)\n",
    "mse_select =np.asarray(mse_select, dtype = np.float)\n",
    "mse_without_select = np.asarray(mse_without_select, dtype = np.float)\n",
    "select, = plt.plot(estimators_list, mse_select, c = 'g', label = \"select line\")\n",
    "without_select, = plt.plot(estimators_list, mse_without_select, c = 'y', label = \"without select\")\n",
    "without_select_bound, = plt.plot(estimators_list, mse_without_select * 1.02, c = 'r', label = \"without select bound\")\n",
    "plt.legend(handles = [select, without_select, without_select_bound])\n",
    "plt.xlabel('cou_estimators')\n",
    "plt.ylabel('mse')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
