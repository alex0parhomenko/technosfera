{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация алгоритма стохастического градиентного бустинга с\n",
    "# квадратичной функцией потерь. В качестве базового алгоритма\n",
    "# использовать алгоритм CART с RSM. ДЗ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART implemention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CART:    \n",
    "    def __init__(self, features_rate, min_samples_leaf, max_depth):\n",
    "        self.features_rate = features_rate\n",
    "        self.tree_map = {}\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        if (max_depth == None):\n",
    "            self.max_depth = 100000\n",
    "        else:\n",
    "            self.max_depth = max_depth\n",
    "\n",
    "    def gen_tree(self, element_numbers, vertex_num, mean, now_depth, mse_value):\n",
    "         \n",
    "        if (now_depth == self.max_depth):  \n",
    "            self.tree_map[str(vertex_num)] = [[None, None], [1], [mean], [None, None]]\n",
    "            return 0\n",
    "        \n",
    "        min_mse = mse_value\n",
    "\n",
    "        pos_num_split = np.nan\n",
    "        value_split = np.nan\n",
    "        \n",
    "        left = []\n",
    "        right = []\n",
    "        \n",
    "        cou_elements = len(element_numbers)\n",
    "        \n",
    "        best_left_square_sum = np.nan\n",
    "        best_left_sum = np.nan\n",
    "        best_right_square_sum = np.nan\n",
    "        best_right_sum = np.nan\n",
    "        \n",
    "        x = self.x[element_numbers]\n",
    "        y = self.y[element_numbers]\n",
    "\n",
    "        for feature_num in range(self.features_cou_analize):\n",
    "\n",
    "            sort_ind = x[:,feature_num].argsort()\n",
    "            new_x = x[:,feature_num][sort_ind]\n",
    "            new_y = y[sort_ind]\n",
    "            \n",
    "            left_cou = 0\n",
    "            right_cou = cou_elements\n",
    "            \n",
    "            del_num = 0\n",
    "            right_square_sum = mse_value + mean * mean * cou_elements * 1.0\n",
    "            right_sum = mean * cou_elements * 1.0\n",
    "            left_square_sum = 0.0\n",
    "            left_sum = 0.0\n",
    "            feature_value_split = np.nan\n",
    "            for i, feature_value in enumerate(new_x):\n",
    "                \n",
    "                if (feature_value_split == feature_value):\n",
    "                    continue\n",
    "                    \n",
    "                if (np.isnan(feature_value_split)):\n",
    "                    feature_value_split = feature_value\n",
    "                else:\n",
    "                    feature_value_split = 0.5 * (feature_value_split + feature_value)\n",
    "                    \n",
    "                while (1):\n",
    "                    if (new_x[del_num] < feature_value_split):\n",
    "                        y_val = new_y[del_num]\n",
    "                        del_num += 1\n",
    "                        left_cou += 1\n",
    "                        right_cou -= 1\n",
    "                        \n",
    "                        left_square_sum += y_val * y_val\n",
    "                        left_sum += y_val\n",
    "                        \n",
    "                        right_square_sum -= y_val * y_val\n",
    "                        right_sum -= y_val\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                if (left_cou < self.min_samples_leaf):\n",
    "                    continue\n",
    "                elif (right_cou < self.min_samples_leaf):\n",
    "                    break\n",
    "                \n",
    "                now_left_mse = left_square_sum - left_sum * left_sum * 1.0/ left_cou\n",
    "                now_right_mse = right_square_sum - right_sum * right_sum * 1.0 / right_cou\n",
    "                \n",
    "                if (now_left_mse + now_right_mse < min_mse):\n",
    "                    min_mse = now_left_mse + now_right_mse\n",
    "                    pos_num_split = feature_num\n",
    "                    value_split = feature_value_split\n",
    "                    \n",
    "                    best_left_square_sum = left_square_sum\n",
    "                    best_left_sum = left_sum\n",
    "                    \n",
    "                    best_right_square_sum = right_square_sum\n",
    "                    best_right_sum = right_sum\n",
    "                    \n",
    "        if (np.isnan(value_split)):\n",
    "            self.tree_map[str(vertex_num)]= [[None, None], [1], [mean], [None, None]]\n",
    "            return 0\n",
    "        \n",
    "        self.tree_map[str(vertex_num)] = [[self.feature_order[pos_num_split], value_split], [0], [mean], [vertex_num*2 + 1, vertex_num*2 + 2]]\n",
    "        \n",
    "        \n",
    "        left_class = []\n",
    "        right_class = []\n",
    "        \n",
    "        for pos in element_numbers:\n",
    "            if (self.x[pos][pos_num_split] < value_split):\n",
    "                left.append(pos)\n",
    "            else:\n",
    "                right.append(pos)\n",
    "\n",
    "        left_mse = best_left_square_sum - (best_left_sum ** 2.0) / len(left)\n",
    "        right_mse = best_right_square_sum - (best_right_sum ** 2.0) / len(right)\n",
    "        \n",
    "        self.feature_contribution[self.feature_order[pos_num_split]] += (mse_value - left_mse - right_mse)\n",
    "        \n",
    "        self.gen_tree(left, vertex_num*2 + 1, best_left_sum * 1.0 / len(left), now_depth + 1, left_mse)\n",
    "        self.gen_tree(right, vertex_num*2 + 2, best_right_sum *1.0/ len(right), now_depth + 1, right_mse)\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.tree_map = {}\n",
    "        \n",
    "        x = np.asarray(x, dtype = np.float)\n",
    "        features_cou = (x.shape)[1]\n",
    "        self.feature_order = np.sort(np.random.choice((x.shape)[1], int((x.shape)[1] * (self.features_rate)), replace=False))\n",
    "        \n",
    "        self.features_cou_analize = int((x.shape)[1] * (self.features_rate))\n",
    "        self.cou_samples = len(x)\n",
    "        \n",
    "        self.feature_contribution = np.zeros(features_cou)\n",
    "        \n",
    "        for i in reversed(range(features_cou)):\n",
    "            if (i not in self.feature_order):\n",
    "                x = np.delete(x, i, 1)\n",
    "\n",
    "        self.x = x\n",
    "        self.y = np.asarray(y, dtype = np.float)\n",
    "        y_pred = np.tile(np.sum(y) * 1.0 / len(y), len(y))\n",
    "        \n",
    "        self.gen_tree(np.arange(self.cou_samples), 0, np.sum(y) * 1.0 / len(y), 0, np.sum((y_pred - self.y) ** 2.0))\n",
    "        \n",
    "        return self.tree_map\n",
    "\n",
    "    def predict(self, data):\n",
    "        y_pred = []\n",
    "        for sample in data:\n",
    "            now_vertex = 0\n",
    "            while (1):\n",
    "                if (self.tree_map[str(now_vertex)][1][0] == 1):\n",
    "                    break\n",
    "                if (sample[self.tree_map[str(now_vertex)][0][0]] >= self.tree_map[str(now_vertex)][0][1]):\n",
    "                    now_vertex = self.tree_map[str(now_vertex)][3][1]\n",
    "                else:\n",
    "                    now_vertex = self.tree_map[str(now_vertex)][3][0]\n",
    "            y_pred.append(self.tree_map[str(now_vertex)][2][0])\n",
    "        return y_pred\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "true_class = []\n",
    "f = open(\"wine.data.txt\", \"r\")\n",
    "f = f.readlines()\n",
    "\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    line = line.split(',')\n",
    "    true_class.append(line[0])\n",
    "    del line[0]\n",
    "    data.append(line)\n",
    "shape_x = len(data)\n",
    "shape_y = len(data[0])\n",
    "\n",
    "data = np.asarray(data, dtype=np.float)\n",
    "true_class = np.asarray(true_class, dtype = np.int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cross Validation for CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My mse 0.0666666666667\n",
      "sklearn mse 0.0666666666667\n",
      "My mse 0.0333333333333\n",
      "sklearn mse 0.0666666666667\n",
      "My mse 0.0\n",
      "sklearn mse 0.0333333333333\n",
      "My mse 0.0666666666667\n",
      "sklearn mse 0.0333333333333\n",
      "My mse 0.0689655172414\n",
      "sklearn mse 0.0344827586207\n",
      "My mse 0.172413793103\n",
      "sklearn mse 0.0689655172414\n",
      "my_mean_mse 0.0680076628352\n",
      "sk_mean_mse 0.0505747126437\n"
     ]
    }
   ],
   "source": [
    "cou_folds = 6\n",
    "kf = KFold(len(data), n_folds=cou_folds, shuffle=True)\n",
    "my_tree = 0.0\n",
    "sk_tree = 0.0\n",
    "cart = CART(1.0, 1, None)\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    x_train, x_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = true_class[train_index], true_class[test_index]\n",
    "    cart.fit(x_train, y_train)\n",
    "    y_pred = cart.predict(x_test)\n",
    "    my_tree += sk.metrics.mean_squared_error(y_test, y_pred)\n",
    "    print 'My mse', sk.metrics.mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    clf = tree.DecisionTreeRegressor(max_depth=None)\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    sk_tree += sk.metrics.mean_squared_error(y_test, y_pred)\n",
    "    print 'sklearn mse', sk.metrics.mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print 'my_mean_mse', my_tree / cou_folds\n",
    "print 'sk_mean_mse', sk_tree / cou_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOCHASTIC GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Stochastic_gradient_boosting:\n",
    "    \n",
    "    def __init__(self, n_estimators, features_rate, cou_samples, min_samples_split, learning_rate, max_depth, loss):\n",
    "        \n",
    "        self.number_elements_in_subsample = cou_samples / n_estimators\n",
    "        self.n_estimators = n_estimators\n",
    "        self.features_rate = features_rate\n",
    "        self.cou_samples = cou_samples\n",
    "        self.loss = loss\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.shrinkage_value = learning_rate\n",
    "        if (max_depth == None):\n",
    "            self.max_depth = 10000\n",
    "        else:\n",
    "            self.max_depth = max_depth\n",
    "    \n",
    "    def get_predict_for_sample_and_one_tree(self, sample, tree_map):\n",
    "        now_vertex = 0\n",
    "        while (1):\n",
    "            if (tree_map[str(now_vertex)][1][0] == 1):\n",
    "                break\n",
    "            if (sample[tree_map[str(now_vertex)][0][0]] >= tree_map[str(now_vertex)][0][1]):\n",
    "                now_vertex = tree_map[str(now_vertex)][3][1]\n",
    "            else:\n",
    "                now_vertex = tree_map[str(now_vertex)][3][0]\n",
    "        return tree_map[str(now_vertex)][2][0]\n",
    "    \n",
    "    def get_predict_for_sample(self, sample):\n",
    "        answer = 0.0\n",
    "        for i in range(len(self.trees_list)):\n",
    "            answer += self.shrinkage_value * self.get_predict_for_sample_and_one_tree(sample, self.trees_list[i][1])\n",
    "        return answer\n",
    "    \n",
    "    def update_grad_for_l2(self, x, tree_map):\n",
    "        for i, sample in enumerate(x):\n",
    "            self.now_grad[i] -= 2.0 * self.get_predict_for_sample_and_one_tree(sample, tree_map) * self.shrinkage_value\n",
    "            \n",
    "    def update_grad_for_l1(self, x, tree_map):\n",
    "        for i, sample in enumerate(x):\n",
    "            pred_for_sample = self.get_predict_for_sample_and_one_tree(sample, tree_map) * self.shrinkage_value\n",
    "            self.y_balance[i] -= pred_for_sample\n",
    "            if (self.y_balance[i] == 0.0):\n",
    "                self.now_grad[i] = 0.00000001\n",
    "            elif (self.y_balance[i] > 0.0):\n",
    "                self.now_grad[i] = 1.0\n",
    "            elif (self.y_balance[i] < 0.0):\n",
    "                self.now_grad[i] = -1.0\n",
    "        \n",
    "        \n",
    "    def predict_regression(self, x):\n",
    "        y_pred = np.zeros(len(x))\n",
    "        for i, sample in enumerate(x):\n",
    "            y_pred[i] = self.get_predict_for_sample(sample)\n",
    "        return y_pred\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.pos_arr = np.arange(self.cou_samples)\n",
    "        self.now_grad = np.array(y, dtype = np.float)\n",
    "        self.trees_list = []\n",
    "        self.y_balance = np.array(y, dtype = np.float)\n",
    "        \n",
    "        cart = CART(self.features_rate, self.min_samples_split, self.max_depth)\n",
    "        \n",
    "        self.feature_contribution = np.zeros((x.shape)[1])\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            np.random.shuffle(self.pos_arr)\n",
    "            index = self.pos_arr[:self.cou_samples / 2]\n",
    "            now_x = x[index]\n",
    "            now_y = self.now_grad[index]\n",
    "            \n",
    "            cart.fit(now_x, now_y)\n",
    "            if (i == 0 and self.loss == 'l2'):\n",
    "                self.now_grad *= 2.0\n",
    "            elif (i == 0 and self.loss == 'l1'):\n",
    "                self.now_grad = np.zeros(len(self.now_grad))\n",
    "                \n",
    "            self.feature_contribution += cart.feature_contribution\n",
    "            \n",
    "            self.trees_list.append([self.shrinkage_value, cart.tree_map])\n",
    "            \n",
    "            if (self.loss == 'l2'):\n",
    "                self.update_grad_for_l2(x, cart.tree_map)\n",
    "            elif (self.loss == 'l1'):\n",
    "                self.update_grad_for_l1(x, cart.tree_map)\n",
    "                \n",
    "        return self.trees_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Stochastic Gradient Boosting on spam Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"spam.train.txt\", \"r\")\n",
    "y_true = []\n",
    "data = []\n",
    "for line in f:\n",
    "    line = line[:len(line) - 1]\n",
    "    arr = line.split(' ')\n",
    "    y_true.append(arr[0])\n",
    "    del arr[0]\n",
    "    data.append(arr)\n",
    "data = np.asarray(data, dtype = np.float)\n",
    "y_true = np.asarray(y_true, dtype = np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"spam.test.txt\", \"r\")\n",
    "test_data = []\n",
    "test_y = []\n",
    "for line in f:\n",
    "    line = line[:len(line) - 1]\n",
    "    arr = line.split(' ')\n",
    "    test_y.append(arr[0])\n",
    "    del arr[0]\n",
    "    test_data.append(arr)\n",
    "    \n",
    "test_data = np.asarray(test_data, dtype = np.float)\n",
    "test_y = np.asarray(test_y, dtype = np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Print plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mse Error 0.0665084082707\n",
      "358.794888\n"
     ]
    }
   ],
   "source": [
    "t1 = time.clock()\n",
    "cou_samples = len(data)\n",
    "original_params = {'n_estimators': 100, 'features_rate': 0.7, 'cou_samples': cou_samples, 'min_samples_split': 4,\n",
    "                'learning_rate' : 0.03, 'max_depth' : 3, 'loss' : \"l2\"}\n",
    "\n",
    "boosting_l2 = Stochastic_gradient_boosting(**original_params)\n",
    "boosting_l2.fit(data, y_true)\n",
    "y_pred = boosting_l2.predict_regression(test_data)\n",
    "print 'Mse Error', sk.metrics.mean_squared_error(test_y, y_pred)\n",
    "print time.clock() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.48111\n"
     ]
    }
   ],
   "source": [
    "t1 = time.clock()\n",
    "estimators_list = np.linspace(30, 100, 8)\n",
    "mse_sklearn = []\n",
    "for cou_estimators in estimators_list:\n",
    "    params = {'n_estimators': int(cou_estimators), 'max_depth': 3, 'min_samples_split': 4,\n",
    "          'learning_rate': 0.03, 'loss': 'ls'}\n",
    "    \n",
    "    clf = ensemble.GradientBoostingRegressor(**params)\n",
    "    clf.fit(data, y_true)\n",
    "    y_pred = clf.predict(test_data)\n",
    "    mse_sklearn.append(sk.metrics.mean_squared_error(test_y, y_pred))\n",
    "print time.clock() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528.161966\n"
     ]
    }
   ],
   "source": [
    "t1 = time.clock()\n",
    "cou_samples = len(data)\n",
    "original_params = {'n_estimators': 100, 'features_rate': 0.7, 'cou_samples': cou_samples, 'min_samples_split': 4,\n",
    "                'learning_rate' : 0.03, 'max_depth' : 3, 'loss' : \"l1\"}\n",
    "\n",
    "boosting_l1 = Stochastic_gradient_boosting(**original_params)\n",
    "boosting_l1.fit(data, y_true)\n",
    "y_pred = boosting_l1.predict_regression(test_data)\n",
    "print time.clock() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGACAYAAACjhWuqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa2d14049d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = test_y.copy()\n",
    "y1 = test_y.copy()\n",
    "my_mse_for_l2 = []\n",
    "my_mse_for_l1 = []\n",
    "cou_samples = len(test_y)\n",
    "y = np.array(y, dtype = np.float)\n",
    "y1 = np.array(y1, dtype = np.float)\n",
    "for i in range(0, 100):\n",
    "    for j, sample in enumerate(test_data):\n",
    "        y[j] -= boosting_l2.get_predict_for_sample_and_one_tree(sample, boosting_l2.trees_list[i][1]) * boosting_l2.shrinkage_value\n",
    "        y1[j] -= boosting_l1.get_predict_for_sample_and_one_tree(sample, boosting_l1.trees_list[i][1]) * boosting_l1.shrinkage_value\n",
    "    if (i + 1 in estimators_list):\n",
    "        my_mse_for_l2.append(np.sum(y ** 2.0) * 1.0 / cou_samples)\n",
    "        my_mse_for_l1.append(np.sum(y1 ** 2.0) * 1.0 / cou_samples)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "mse_sklearn = np.asarray(mse_sklearn, dtype = np.float)\n",
    "estimators_list = np.asarray(estimators_list, dtype = np.float)\n",
    "plt.figure(figsize = (8, 6), dpi = 80)\n",
    "plt.xlabel('cou_estimators')\n",
    "plt.ylabel('sklearn regression boosting error')\n",
    "plt.plot(estimators_list, mse_sklearn, 'b')\n",
    "plt.plot(estimators_list, mse_sklearn * 1.03, c = 'r')\n",
    "plt.plot(estimators_list, my_mse_for_l2, c = 'g')\n",
    "plt.plot(estimators_list, my_mse_for_l1, c = 'y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализовать embedded метод отбора признаков для\n",
    "# своего варианта из дз 1. Провести сравнительный анализ своего\n",
    "# метода с каждым из подходов, описанных на лекции (т.е. нужно\n",
    "# минимум реализовать один wrapper и один filter метод). Построить\n",
    "# графики. ДЗ2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Implemention embedded method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def emdedded_method(params, data, y_true, cou_features):\n",
    "    t1 = time.clock()\n",
    "    boosting = Stochastic_gradient_boosting(**params)\n",
    "    boosting.fit(data, y_true)\n",
    "    a = boosting.feature_contribution\n",
    "    f_contrib = []\n",
    "    for feature_num, feature_contribution in enumerate(a):\n",
    "        f_contrib.append([feature_contribution, feature_num])\n",
    "        \n",
    "    f_contrib = sorted(f_contrib, reverse= True)\n",
    "    f_contrib = np.asarray(f_contrib, dtype = np.float)\n",
    "    \n",
    "    result_positions = []\n",
    "    for i in range(cou_features):\n",
    "        result_positions.append(f_contrib[i][1])\n",
    "    \n",
    "    '''split_pos = -1\n",
    "    for i in range(len(f_contrib)):\n",
    "        if (np.sum(f_contrib[:i,0]) > np.sum(f_contrib[i:,0])):\n",
    "            split_pos = i\n",
    "            break\n",
    "    feature_positions = []\n",
    "    for i in range(0,split_pos):\n",
    "        feature_positions.append(f_contrib[i][1])\n",
    "\n",
    "    feature_positions = np.asarray(feature_positions, dtype = np.int)'''\n",
    "    return result_positions, time.clock() - t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators': 50, 'features_rate': 1.0, 'cou_samples': len(data), 'min_samples_split': 40,\n",
    "                    'learning_rate' : 0.06, 'max_depth' : None, 'loss' : 'l2'}\n",
    "cou_features = 6\n",
    "features_embedded, time_embedded = emdedded_method(params, data, y_true, cou_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 48 101  70   8] 959.652329\n"
     ]
    }
   ],
   "source": [
    "print features_embedded, time_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Implemention Wrapper method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward_selection(data, y_true, hopelessness_value, loss):\n",
    "    start_time = time.clock()\n",
    "    \n",
    "    data = np.asarray(data, np.float)\n",
    "    y_true = np.asarray(y_true, np.float)\n",
    "    \n",
    "    features_set = []\n",
    "    features_cou = (data.shape)[1]\n",
    "    Q = 100000.0\n",
    "    for i in range(features_cou):\n",
    "        best_feature = -1\n",
    "        for j in range(features_cou):\n",
    "            #print j\n",
    "            now_x = data.copy()\n",
    "            if (j not in features_set):\n",
    "                now_set = list(features_set)\n",
    "                now_set.append(j)\n",
    "                for del_pos in reversed(range(features_cou)):\n",
    "                    if (del_pos not in now_set):\n",
    "                        now_x = np.delete(now_x, del_pos, axis = 1)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "\n",
    "            cou_folds = 5\n",
    "            kf = KFold(len(data), n_folds=cou_folds, shuffle=True)\n",
    "            mse_value_for_now_feature = 0.0\n",
    "            for train_index, test_index in kf:\n",
    "                x_train, x_test = now_x[train_index], now_x[test_index]\n",
    "                y_train, y_test = y_true[train_index], y_true[test_index]\n",
    "                \n",
    "                params = {'n_estimators': 50, 'max_depth': 3, 'min_samples_split': 4,\n",
    "                      'learning_rate': 0.03, 'loss': 'ls'}\n",
    "                \n",
    "                clf = ensemble.GradientBoostingRegressor(**params)\n",
    "                clf.fit(x_train, y_train)\n",
    "                y_pred = clf.predict(x_test)\n",
    "                mse_value_for_now_feature += sk.metrics.mean_squared_error(y_test, y_pred)\n",
    "\n",
    "            \n",
    "            mse_value_for_now_feature /= cou_folds\n",
    "            if (mse_value_for_now_feature < Q * hopelessness_value):\n",
    "                Q = mse_value_for_now_feature\n",
    "                best_feature = j\n",
    "        if (best_feature == -1):\n",
    "            break\n",
    "        features_set.append(best_feature)\n",
    "    return features_set, time.clock() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "features_forward_selection, time_forward_selection = forward_selection(data, y_true, 0.9, \"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48, 4, 8, 71] 472.801651\n"
     ]
    }
   ],
   "source": [
    "print features_forward_selection, time_forward_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corelation Feature Selection implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def corelation_feature_selection(x, y):\n",
    "    features_cou = (x.shape)[1]\n",
    "    samples_cou = len(y)\n",
    "    corelation_target = np.zeros(features_cou, dtype = np.float)\n",
    "    \n",
    "    pair_feature_corelation = np.zeros(shape = (features_cou, features_cou))\n",
    "    for pos in range(features_cou):\n",
    "        y_mean = np.tile(np.sum(y) / samples_cou, samples_cou)\n",
    "        now_feature = x[:,pos]\n",
    "        now_feature_mean = np.tile(np.sum(now_feature) / features_cou, samples_cou)\n",
    "        corelation_target[pos] = np.sum((y - y_mean) * (now_feature - now_feature_mean)) / np.sqrt(np.sum((y - y_mean) ** 2) * np.sum((now_feature - now_feature_mean) ** 2))\n",
    "    \n",
    "    for first_pos in range(features_cou):\n",
    "        first_feature = x[:, first_pos]\n",
    "        first_feature_mean = np.tile(np.sum(first_feature) / samples_cou, samples_cou)\n",
    "        for second_pos in range(features_cou):\n",
    "            second_feature = x[:, second_pos]\n",
    "            second_feature_mean = np.tile(np.sum(second_feature) / samples_cou, samples_cou)\n",
    "            pair_feature_corelation[first_pos][second_pos] = np.sum((first_feature - first_feature_mean) * (second_feature - second_feature_mean)) / np.sqrt(np.sum((first_feature - first_feature_mean) ** 2) * np.sum((second_feature - second_feature_mean) ** 2))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corelation_feature_selection(data, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
