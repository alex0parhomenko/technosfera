{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "import theano.tensor as th\n",
    "from scipy import misc\n",
    "import copy\n",
    "from numpy.random import uniform\n",
    "from numpy.random import normal\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_classification\n",
    "from math import copysign\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autoencoder + rmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class rbm:\n",
    "    def __init__(self, learning_rate, mu_moment, batch_size, num_epochs, hidden_count, mode):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.mu_moment = mu_moment\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.hidden_count = hidden_count\n",
    "        self.mode = mode\n",
    "        \n",
    "    def sigmoid(self, matrix):\n",
    "        return 1. / (1. + np.exp(-matrix))\n",
    "    \n",
    "    def init_weights(self, vis_count):\n",
    "        self.w_vh = np.random.normal(0, 0.1, (vis_count, self.hidden_count))\n",
    "        self.w_v = np.zeros(vis_count)\n",
    "        self.w_h = np.zeros(self.hidden_count)\n",
    "        \n",
    "        self.wu_vh = np.zeros((vis_count, self.hidden_count))\n",
    "        self.wu_v = np.zeros(vis_count)\n",
    "        self.wu_h = np.zeros(self.hidden_count)\n",
    "    \n",
    "    def fit(self, x):\n",
    "        self.init_weights(x.shape[1])\n",
    "        sample_size = x.shape[0]\n",
    "        shuffle(x)\n",
    "        \n",
    "        test_data = x[:(sample_size * 0.1)]\n",
    "        x = x[(sample_size * 0.1):]\n",
    "        \n",
    "        batch_count = (x.shape[0]) // self.batch_size\n",
    "        start_time = time.time()\n",
    "        for epoch in range(self.num_epochs):\n",
    "            print \"Epoch num:\", epoch+1\n",
    "            err = []\n",
    "            shuffle(x)\n",
    "            for batch in range(batch_count):\n",
    "                v = x[batch * self.batch_size : (batch + 1) * self.batch_size]\n",
    "                v_true = v.copy()\n",
    "                \n",
    "                self.wu_vh *= self.mu_moment\n",
    "                self.wu_v *= self.mu_moment\n",
    "                self.wu_h *= self.mu_moment\n",
    "                \n",
    "                #positive phase\n",
    "                h = self.sigmoid(np.dot(v, self.w_vh) + self.w_h)\n",
    "                \n",
    "                self.wu_vh += np.dot(v.T, h)\n",
    "                self.wu_v += np.sum(v, axis = 0)\n",
    "                self.wu_h += np.sum(h, axis = 0)\n",
    "                    \n",
    "                #sampling\n",
    "                h = 1. * (np.random.uniform(0, 1, (self.batch_size, self.hidden_count)) < h)\n",
    "                \n",
    "                #negative phase \n",
    "                if self.mode == 'gaussian':\n",
    "                    v = np.dot(h, self.w_vh.T) + self.w_v\n",
    "                elif self.mode == 'bernoulli':\n",
    "                    v = self.sigmoid(np.dot(h, self.w_vh.T) + self.w_v)\n",
    "                    \n",
    "                h = self.sigmoid(np.dot(v, self.w_vh) + self.w_h)\n",
    "                \n",
    "                #update weights\n",
    "                self.wu_vh -= np.dot(v.T, h)\n",
    "                self.wu_v -= np.sum(v, axis = 0)\n",
    "                self.wu_h -= np.sum(h, axis = 0)\n",
    "                \n",
    "                self.w_vh += self.wu_vh * self.learning_rate / self.batch_size\n",
    "                self.w_v += self.wu_v * self.learning_rate / self.batch_size\n",
    "                self.w_h += self.wu_h * self.learning_rate / self.batch_size\n",
    "                \n",
    "                err.append(np.mean((v - v_true) ** 2))\n",
    "                \n",
    "            print 'Time is:', time.time() - start_time\n",
    "            print 'Error is:', np.mean(err)\n",
    "            h, pred = self.predict(test_data)\n",
    "            print 'Error for test data:', np.mean((test_data - pred) ** 2)\n",
    "                \n",
    "    def predict(self, x):        \n",
    "        h = np.dot(x, self.w_vh)\n",
    "        h += np.tile(self.w_h, (x.shape[0], 1))\n",
    "        h = self.sigmoid(h)\n",
    "        h_ret = h.copy()\n",
    "        h = (np.random.uniform(0, 1, (x.shape[0], self.hidden_count)) < h) * 1.\n",
    "        \n",
    "        pred = np.dot(h, self.w_vh.T)\n",
    "        pred += np.tile(self.w_v, (x.shape[0], 1))\n",
    "        pred = self.sigmoid(pred)\n",
    "        return h_ret, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class autoencoder:\n",
    "    def __init__(self, layers_list, learning_rate, alpha, activation_functions, cost_func, \\\n",
    "                 epochs_count, batch_size,\\\n",
    "                  sparse_num, weight_list):\n",
    "        \n",
    "        self.layers_count = len(layers_list) -1\n",
    "        self.weight_list = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers_list = layers_list\n",
    "        self.alpha = alpha\n",
    "        self.cost_func = cost_func\n",
    "        self.activation_functions = activation_functions\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs_count = epochs_count\n",
    "        self.sparse_num = sparse_num\n",
    "        self.weight_list = weight_list\n",
    "            \n",
    "    def sigmoid(self, x):\n",
    "        m = 1. / (1. + np.exp(-x * self.alpha))\n",
    "        m = np.fmax(m, 0.001)\n",
    "        m = np.fmin(m, 0.999)\n",
    "        return m\n",
    "    \n",
    "    def der_sigmoid(self, x):\n",
    "        return (1. - self.sigmoid(x)) * self.sigmoid(x) * self.alpha\n",
    "    \n",
    "    def square_cost_vec(self, y_true, y_pred):\n",
    "        return 0.5 * ((y_true - y_pred) ** 2)\n",
    "    \n",
    "    def der_square_cost_vec(self, y_true, y_pred):\n",
    "        return (y_pred - y_true)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        sparse_decode = None\n",
    "        output = None\n",
    "        neuron_out = x\n",
    "        for num_layer in range(self.layers_count):\n",
    "            neuron_out = np.dot(neuron_out, self.weight_list[num_layer])\n",
    "            \n",
    "            if (self.activation_functions[num_layer + 1] == 'sigmoid'):\n",
    "                neuron_out = self.sigmoid(neuron_out)\n",
    "\n",
    "            if (num_layer + 1 == self.sparse_num):\n",
    "                sparse_decode = neuron_out\n",
    "                \n",
    "            if (num_layer == self.layers_count - 1):\n",
    "                output = neuron_out\n",
    "        \n",
    "            neuron_out = np.insert(neuron_out, 0, -1, axis = 1)\n",
    "            \n",
    "        return sparse_decode, output\n",
    "    \n",
    "    def get_error(self, x, y):\n",
    "        sparse, out = self.predict(x)\n",
    "        y_err = np.sum((out - y) ** 2) / (x.shape[0] * x.shape[1])\n",
    "        return y_err\n",
    "    \n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        batch_count = x.shape[0] // self.batch_size\n",
    "\n",
    "        x = np.insert(x, 0, -1, axis = 1)\n",
    "        y = np.insert(y, 0, -1, axis = 1)\n",
    "        shuffle(x, y)\n",
    "        x_test = x[0.95 * x.shape[0]:]\n",
    "        x = x[:0.95 * x.shape[0]]\n",
    "        \n",
    "        y_test = y[0.95 * y.shape[0]:]\n",
    "        y = y[:0.95 * y.shape[0]]\n",
    "        \n",
    "        for num_epoch in range(self.epochs_count):\n",
    "            print \"Epoch num is: \", num_epoch\n",
    "            print \"err is:\", self.get_error(x_test, y_test)\n",
    "            shuffle(x, y)\n",
    "            for batch_num in range(batch_count):\n",
    "                data = x[batch_num * self.batch_size:(batch_num + 1) * self.batch_size]\n",
    "                data_true = y[batch_num * self.batch_size:(batch_num + 1) * self.batch_size]\n",
    "                \n",
    "                neuron_out = [data]\n",
    "                neuron_sum = [data[:, 1:]]\n",
    "                w_u = []\n",
    "                for num_layer in range(self.layers_count):\n",
    "                    s = np.dot(neuron_out[-1], self.weight_list[num_layer])\n",
    "                    neuron_sum.append(s)\n",
    "                    if (self.activation_functions[num_layer + 1] == 'sigmoid'):\n",
    "                        s = self.sigmoid(s)\n",
    "                    if (num_layer != self.layers_count - 1):\n",
    "                        s = np.insert(s, 0, -1, axis = 1)\n",
    "                    neuron_out.append(s)\n",
    "\n",
    "                if (self.cost_func == 'square'):\n",
    "                    der_neuron = self.der_square_cost_vec(data_true[:, 1:], neuron_out[-1])\n",
    "\n",
    "                for layer_num in range(self.layers_count - 1, -1, -1):\n",
    "                    w_u.insert(0, np.sum( map(lambda x, y: np.dot(x.reshape(-1, 1), y.reshape(1, -1)), neuron_out[layer_num], der_neuron), axis = 0))\n",
    "                    if self.activation_functions[layer_num] == 'sigmoid':\n",
    "                        der_neuron = np.dot(der_neuron, self.weight_list[layer_num].T)[:, 1:] * self.der_sigmoid(neuron_sum[layer_num])\n",
    "                    \n",
    "                self.weight_list = map(lambda x, y: x - y * (self.learning_rate / self.batch_size), self.weight_list, w_u)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('mnist.csv', sep = ',')\n",
    "data = np.asarray(data)\n",
    "target = data[:, 1]\n",
    "data = data[:, 1:] / 255.\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:27: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 1\n",
      "Time is: 218.540069103\n",
      "Error is: 0.0397568469087\n",
      "Error for test data: 0.0259837256758\n",
      "Epoch num: 2\n",
      "Time is: 452.471276045\n",
      "Error is: 0.0226902799886\n",
      "Error for test data: 0.0206547065126\n"
     ]
    }
   ],
   "source": [
    "rbm_first_layer = rbm(learning_rate = 0.005, mu_moment = 0.9, batch_size = 200, num_epochs = 2, hidden_count = 500,\\\n",
    "           mode= 'bernoulli')\n",
    "rbm_first_layer.fit(data)\n",
    "h, pred = rbm_first_layer.predict(data)\n",
    "w_vh1 = rbm_first_layer.w_vh\n",
    "w_v1 = rbm_first_layer.w_v\n",
    "w_h1 = rbm_first_layer.w_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:27: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 1\n",
      "Time is: 115.405921936\n",
      "Error is: 0.0517354420641\n",
      "Error for test data: 0.0325000583121\n",
      "Epoch num: 2\n",
      "Time is: 222.030552864\n",
      "Error is: 0.0287600820124\n",
      "Error for test data: 0.0263532871586\n"
     ]
    }
   ],
   "source": [
    "rbm_second_layer = rbm(learning_rate = 0.005, mu_moment = 0.9, batch_size = 200, num_epochs = 2, hidden_count = 500,\\\n",
    "           mode= 'bernoulli')\n",
    "rbm_second_layer.fit(h)\n",
    "h, pred = rbm_second_layer.predict(h)\n",
    "w_vh2 = rbm_second_layer.w_vh\n",
    "w_v2 = rbm_second_layer.w_v\n",
    "w_h2 = rbm_second_layer.w_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate third layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:27: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 1\n",
      "Time is: 7.38730192184\n",
      "Error is: 0.0603864900101\n",
      "Error for test data: 0.0389987361711\n",
      "Epoch num: 2\n",
      "Time is: 16.4116020203\n",
      "Error is: 0.0336365695202\n",
      "Error for test data: 0.0300338805671\n",
      "Epoch num: 3\n",
      "Time is: 24.0292189121\n",
      "Error is: 0.0277019223726\n",
      "Error for test data: 0.0260544694137\n",
      "Epoch num: 4\n",
      "Time is: 31.9193639755\n",
      "Error is: 0.0246212304056\n",
      "Error for test data: 0.02373476232\n",
      "Epoch num: 5\n",
      "Time is: 40.2244138718\n",
      "Error is: 0.0227092014048\n",
      "Error for test data: 0.0222051797573\n"
     ]
    }
   ],
   "source": [
    "rbm_spy = rbm(learning_rate = 0.005, mu_moment = 0.9, batch_size = 200, num_epochs = 2, hidden_count = 32,\\\n",
    "           mode= 'bernoulli')\n",
    "rbm_spy.fit(h)\n",
    "h, pred = rbm_spy.predict(h)\n",
    "w_vh3 = rbm_spy.w_vh\n",
    "w_v3 = rbm_spy.w_v\n",
    "w_h3 = rbm_spy.w_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_layer = np.insert(w_vh1, 0, w_h1, axis = 0)\n",
    "second_layer = np.insert(w_vh2, 0, w_h2, axis = 0)\n",
    "third_layer = np.insert(w_vh3, 0, w_h3, axis = 0)\n",
    "a = w_vh3.T\n",
    "b = w_vh2.T\n",
    "c = w_vh1.T\n",
    "fouth_layer = np.insert(a, 0, w_v3, axis = 0)\n",
    "fith_layer = np.insert(b, 0, w_v2, axis = 0)\n",
    "sixth_layer = np.insert(c, 0, w_v1, axis = 0)\n",
    "\n",
    "weight_list = [first_layer, second_layer, third_layer, fouth_layer, fith_layer, sixth_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:63: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:64: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:66: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:67: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num is:  0\n",
      "err is:"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (2100,785) and (786,500) not aligned: 785 (dim 1) != 786 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-ca29abf2e56c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m784\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m                          \u001b[0mactivation_functions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m                         \u001b[0mcost_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'square'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m                         \u001b[0msparse_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-91-f65f4c40eb7f>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Epoch num is: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"err is:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-91-f65f4c40eb7f>\u001b[0m in \u001b[0;36mget_error\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0my_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-91-f65f4c40eb7f>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mneuron_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnum_layer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mneuron_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneuron_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_functions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_layer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2100,785) and (786,500) not aligned: 785 (dim 1) != 786 (dim 0)"
     ]
    }
   ],
   "source": [
    "encoder = autoencoder(layers_list = [784, 500, 500, 32, 500, 500, 784], learning_rate = 0.001, alpha = 1.0,\\\n",
    "                          activation_functions = ['x', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'x'],\\\n",
    "                         cost_func = 'square', epochs_count = 15, batch_size = 200,\\\n",
    "                         sparse_num = 3, weight_list = weight_list)\n",
    "encoder.fit(data + normal(0, 1, (data.shape[0], data.shape[1])), data)\n",
    "\n",
    "decode, real = encoder.predict(np.insert(data, 0, -1, axis = 1))\n",
    "print np.mean((x_test - real) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, perplexity=30.0, early_exaggeration=4.0,\\\n",
    "            learning_rate=1000.0, n_iter=1000, n_iter_without_progress=30, min_grad_norm=1e-07,\\\n",
    "            metric='euclidean', init='random', verbose=0, random_state=None, method='barnes_hut', angle=0.5)\n",
    "\n",
    "x = tsne.fit_transform(data)\n",
    "\n",
    "plt.figure(figsize = (8, 6), dpi = 80)\n",
    "plt.scatter(x[:, 0], x[:, 1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
