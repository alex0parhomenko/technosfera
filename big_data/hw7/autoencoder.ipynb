{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "import theano.tensor as th\n",
    "from scipy import misc\n",
    "import copy\n",
    "from numpy.random import uniform\n",
    "from numpy.random import normal\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_classification\n",
    "from math import copysign\n",
    "from numpy.random import normal\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class autoencoder:\n",
    "    def __init__(self, layers_list, learning_rate, alpha, activation_functions, cost_func, \\\n",
    "                 epochs_count, batch_size,\\\n",
    "                  sparse_num, weight_list):\n",
    "        \n",
    "        self.layers_count = len(layers_list) -1\n",
    "        self.weight_list = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers_list = layers_list\n",
    "        self.alpha = alpha\n",
    "        self.cost_func = cost_func\n",
    "        self.activation_functions = activation_functions\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs_count = epochs_count\n",
    "        self.sparse_num = sparse_num\n",
    "        self.weight_list = weight_list\n",
    "            \n",
    "    def sigmoid(self, x):\n",
    "        m = 1. / (1. + np.exp(-x * self.alpha))\n",
    "        m = np.fmax(m, 0.001)\n",
    "        m = np.fmin(m, 0.999)\n",
    "        return m\n",
    "    \n",
    "    def der_sigmoid(self, x):\n",
    "        return (1. - self.sigmoid(x)) * self.sigmoid(x) * self.alpha\n",
    "    \n",
    "    def square_cost_vec(self, y_true, y_pred):\n",
    "        return 0.5 * ((y_true - y_pred) ** 2)\n",
    "    \n",
    "    def der_square_cost_vec(self, y_true, y_pred):\n",
    "        return (y_pred - y_true)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        sparse_decode = None\n",
    "        output = None\n",
    "        neuron_out = x\n",
    "        #print x.shape\n",
    "        for num_layer in range(self.layers_count):\n",
    "            neuron_out = np.dot(neuron_out, self.weight_list[num_layer])\n",
    "            \n",
    "            if (self.activation_functions[num_layer + 1] == 'sigmoid'):\n",
    "                neuron_out = self.sigmoid(neuron_out)\n",
    "\n",
    "            if (num_layer + 1 == self.sparse_num):\n",
    "                sparse_decode = neuron_out\n",
    "                \n",
    "            if (num_layer == self.layers_count - 1):\n",
    "                output = neuron_out\n",
    "        \n",
    "            neuron_out = np.insert(neuron_out, 0, -1, axis = 1)\n",
    "            \n",
    "        return sparse_decode, output\n",
    "    \n",
    "    def get_error(self, x, y):\n",
    "        sparse, out = self.predict(x)\n",
    "        y_err = np.sum((out - y) ** 2) / (x.shape[0] * x.shape[1])\n",
    "        return y_err\n",
    "    \n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        batch_count = x.shape[0] // self.batch_size\n",
    "\n",
    "        x = np.insert(x, 0, -1, axis = 1)\n",
    "        y = np.insert(y, 0, -1, axis = 1)\n",
    "        shuffle(x, y)\n",
    "        x_test = x[0.95 * x.shape[0]:]\n",
    "        x = x[:0.95 * x.shape[0]]\n",
    "        \n",
    "        y_test = y[0.95 * y.shape[0]:]\n",
    "        y = y[:0.95 * y.shape[0]]\n",
    "        \n",
    "        for num_epoch in range(self.epochs_count):\n",
    "            print \"Epoch num is: \", num_epoch\n",
    "            print \"err is:\", self.get_error(x_test, y_test[:, 1:])\n",
    "            shuffle(x, y)\n",
    "            for batch_num in range(batch_count):\n",
    "                data = x[batch_num * self.batch_size:(batch_num + 1) * self.batch_size]\n",
    "                data_true = y[batch_num * self.batch_size:(batch_num + 1) * self.batch_size]\n",
    "                \n",
    "                neuron_out = [data]\n",
    "                neuron_sum = [data[:, 1:]]\n",
    "                w_u = []\n",
    "                for num_layer in range(self.layers_count):\n",
    "                    s = np.dot(neuron_out[-1], self.weight_list[num_layer])\n",
    "                    neuron_sum.append(s)\n",
    "                    if (self.activation_functions[num_layer + 1] == 'sigmoid'):\n",
    "                        s = self.sigmoid(s)\n",
    "                    if (num_layer != self.layers_count - 1):\n",
    "                        s = np.insert(s, 0, -1, axis = 1)\n",
    "                    neuron_out.append(s)\n",
    "\n",
    "                if (self.cost_func == 'square'):\n",
    "                    der_neuron = self.der_square_cost_vec(data_true[:, 1:], neuron_out[-1])\n",
    "\n",
    "                for layer_num in range(self.layers_count - 1, -1, -1):\n",
    "                    w_u.insert(0, np.sum( map(lambda x, y: np.dot(x.reshape(-1, 1), y.reshape(1, -1)), neuron_out[layer_num], der_neuron), axis = 0))\n",
    "                    if self.activation_functions[layer_num] == 'sigmoid':\n",
    "                        der_neuron = np.dot(der_neuron, self.weight_list[layer_num].T)[:, 1:] * self.der_sigmoid(neuron_sum[layer_num])\n",
    "                    \n",
    "                self.weight_list = map(lambda x, y: x - y * (self.learning_rate / self.batch_size), self.weight_list, w_u)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = misc.imread('data/big_alphabet_29x29/mutant-0-0-0.bmp', flatten='grey')\n",
    "alphabet_size = 26\n",
    "im_size = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "for letter in range(alphabet_size):\n",
    "    for i in range(9):\n",
    "        path = \"data/big_alphabet_29x29/mutant-\" + str(letter) + \"-\" + str(i) + \"-0.bmp\"\n",
    "        im = misc.imread(path, flatten='grey')\n",
    "        x.append(im.reshape(im_size * im_size))\n",
    "        x[-1] /= 255.0\n",
    "\n",
    "for letter in range(alphabet_size):\n",
    "    path = \"data/big_alphabet_29x29/class-\" + str(letter) + \".bmp\"\n",
    "    im = misc.imread(path, flatten='grey')\n",
    "    x_test.append(im.reshape(im_size * im_size))\n",
    "    x_test[-1] /= 255.\n",
    "\n",
    "    \n",
    "x = np.asarray(x)\n",
    "y = x.copy()\n",
    "x_test = np.asarray(x_test)\n",
    "y_test = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234, 841) (234, 841)\n"
     ]
    }
   ],
   "source": [
    "print x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_list = [normal(0, 0.1, (842, 500)), normal(0, 0.1, (501, 500)), normal(0, 0.1, (501, 32)), \\\n",
    "              normal(0, 0.1, (33, 500)), normal(0, 0.1, (501, 500)), normal(0, 0.1, (501, 841))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:64: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:65: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:67: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:68: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num is:  0\n",
      "err is: 2.26342333424\n",
      "Epoch num is:  1\n",
      "err is: 0.173681498649\n",
      "Epoch num is:  2\n",
      "err is: 0.0665532443165\n",
      "Epoch num is:  3\n",
      "err is: 0.0587958522808\n",
      "Epoch num is:  4\n",
      "err is: 0.0581776926403\n",
      "Epoch num is:  5\n",
      "err is: 0.0581143600701\n",
      "Epoch num is:  6\n",
      "err is: 0.0581051337722\n",
      "Epoch num is:  7\n",
      "err is: 0.0581033150693\n",
      "Epoch num is:  8\n",
      "err is: 0.0581028897088\n",
      "Epoch num is:  9\n",
      "err is: 0.058102782468\n",
      "Epoch num is:  10\n",
      "err is: 0.0581027551824\n",
      "Epoch num is:  11\n",
      "err is: 0.058102749016\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-41ea9eeaf805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mauto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m841\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m841\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m                \u001b[0mactivation_functions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m                         \u001b[0mcost_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'square'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m                          \u001b[0msparse_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mauto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mauto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-420a34948a3f>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[0mw_u\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mnum_layer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneuron_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m                     \u001b[0mneuron_sum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_functions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_layer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "auto = autoencoder(layers_list = [841, 500, 500, 32, 500, 500, 841], learning_rate = 0.001, alpha = 1.0,\\\n",
    "                activation_functions = ['x', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'x'],\\\n",
    "                         cost_func = 'square', epochs_count = 1000, batch_size = 25,\\\n",
    "                          sparse_num = 1, weight_list = weight_list)\n",
    "auto.fit(x + normal(0, 1, (x.shape[0], x.shape[1])), x)\n",
    "auto.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
