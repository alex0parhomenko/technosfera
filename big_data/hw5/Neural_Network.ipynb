{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "import theano.tensor as th\n",
    "from scipy import misc\n",
    "import copy\n",
    "from numpy.random import uniform\n",
    "from numpy.random import normal\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class network:\n",
    "    def __init__(self, layers_list, learning_rate, alpha, activation_functions, cost_func):\n",
    "        self.layers_count = len(layers_list)\n",
    "        self.weight_list = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers_list = layers_list\n",
    "        self.alpha = alpha\n",
    "        self.cost_func = cost_func\n",
    "        self.activation_function = activation_functions\n",
    "        for i in range(1, self.layers_count):\n",
    "            m = np.asarray(uniform(-1, 1, (self.layers_list[i - 1] + 1, self.layers_list[i])))\n",
    "            self.weight_list.append(m)\n",
    "            \n",
    "    def w_out(self):\n",
    "        for i in range(len(self.weight_list)):\n",
    "            print self.weight_list[i]\n",
    "            print '\\n'\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        one = np.ones(len(x))\n",
    "        return one / (one + np.exp(-x * self.alpha))\n",
    "    \n",
    "    def der_sigmoid(self, x):\n",
    "        one = np.ones(len(x))\n",
    "        return (one - self.sigmoid(x)) * self.sigmoid(x) * self.alpha\n",
    "    \n",
    "    def hyp_tg(self, x):\n",
    "        return (np.exp(self.alpha * x) - np.exp(-self.alpha * x)) / (np.exp(self.alpha * x) + np.exp(-self.alpha * x))\n",
    "    \n",
    "    def der_hyp_tg(self, x):\n",
    "        return self.alpha * (1 - hyp_tg(x) ** 2)\n",
    "    \n",
    "    def der_logistic_cost(self, y_true, y_pred):\n",
    "        return ((1.0 - y_true) / (1.0 - y_pred) - y_true / y_pred)\n",
    "    \n",
    "    def logistic_cost(self, y_true, y_pred):\n",
    "        return -1.0 * (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    \n",
    "    def square_cost(self, y_true, y_pred):\n",
    "        return 0.5 * ((y_true - y_pred) ** 2)\n",
    "    \n",
    "    def der_square_cost(self, y_true, y_pred):\n",
    "        return y_pred - y_true\n",
    "    \n",
    "    def add_first_layer(self, x_shape):\n",
    "        self.weight_list.insert(0, np.asarray(uniform(-1, 1, (x_shape, self.layers_list[0]))))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = np.asarray(x)\n",
    "        x = np.insert(x, 0, [-1], axis = 1)\n",
    "        ans = []\n",
    "        for s_num, sample in enumerate(x):\n",
    "            v = sample\n",
    "            for num, layer in enumerate(self.weight_list):\n",
    "                v = np.dot(layer.T, v)\n",
    "                v = self.sigmoid(v)\n",
    "                if (num != self.layers_count - 1):\n",
    "                    v = np.insert(v, 0, [-1])\n",
    "            ans.append(v)\n",
    "        return ans\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        x = np.insert(x, 0, -1, axis = 1)\n",
    "        self.add_first_layer(x.shape[1])\n",
    "        \n",
    "        cou_iter = 400\n",
    "        k = 0\n",
    "        while (k < cou_iter):\n",
    "            for s_num, sample in enumerate(x):\n",
    "                neuron_sum = []\n",
    "                neuron_out = []\n",
    "                neuron_out.append(np.asarray(sample, dtype = np.float))\n",
    "                v = sample\n",
    "                for num, layer in enumerate(self.weight_list):\n",
    "                    v = np.dot(layer.T, v)\n",
    "                    neuron_sum.append(v)\n",
    "                    v = self.sigmoid(v)\n",
    "                    if (num != self.layers_count - 1):\n",
    "                        v = np.insert(v, 0, [-1])\n",
    "                    neuron_out.append(v)\n",
    "                    \n",
    "                num = 0\n",
    "                der_neuron = []\n",
    "                for layer in reversed(self.weight_list):\n",
    "                    if (num == 0):\n",
    "                        der = (self.der_logistic_cost(y[s_num], neuron_out[-1][0]) * self.der_sigmoid(neuron_sum[-1]))\n",
    "                        der_neuron.append(der)\n",
    "                        num += 1\n",
    "                        #if (num == self.layers_count):\n",
    "                        #    break\n",
    "                        #print 'all good'\n",
    "                        #print np.dot(layer[1😏, der) * self.der_sigmoid(neuron_sum[len(neuron_sum) - num - 1])\n",
    "                        #return 0\n",
    "                        #der = (layer[1😏).T * np.tile(der, len(layer) - 1) * self.der_sigmoid(neuron_sum[len(neuron_sum) - num - 1])\n",
    "                        #der_neuron.insert(0, der[0])\n",
    "                        #num += 1\n",
    "                    else:\n",
    "                        if (num == self.layers_count):\n",
    "                            break\n",
    "\n",
    "                    der = np.dot(layer[1, der_neuron[0]) * self.der_sigmoid(neuron_sum[len(neuron_sum) - num - 1])\n",
    "                        der_neuron.insert(0, der)\n",
    "                        num += 1\n",
    "                        \n",
    "                for layer_num in range(self.layers_count):\n",
    "                    layer = self.weight_list[self.layers_count - layer_num - 1]\n",
    "                    result_layer = layer.copy()\n",
    "                    layer = np.asarray(layer, dtype = np.float)\n",
    "                    for pos, row in enumerate(layer):\n",
    "                        row1 = row - self.learning_rate * der_neuron[len(der_neuron) - layer_num - 1] * neuron_out[len(neuron_out) - layer_num - 2][pos]\n",
    "                        result_layer[pos] = row1\n",
    "                    self.weight_list[self.layers_count - layer_num - 1] = result_layer\n",
    "                \n",
    "            k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 1.87453742]), array([ 1.861004]), array([ 1.85031868]), array([ 1.85318386]), array([ 1.8713455]), array([ 1.89996495]), array([ 1.85095966]), array([ 1.87337447]), array([ 1.83798309]), array([ 1.86731642]), array([ 1.8926337]), array([ 1.8689746]), array([ 1.85793657]), array([ 1.822932]), array([ 1.89956942]), array([ 1.90857634]), array([ 1.88446515]), array([ 1.87336702]), array([ 1.91174469]), array([ 1.8802971]), array([ 1.89744418]), array([ 1.87816836]), array([ 1.83734165]), array([ 1.88083574]), array([ 1.88088547]), array([ 1.87328083]), array([ 1.87498194]), array([ 1.88263263]), array([ 1.87769327]), array([ 1.86265724]), array([ 1.86588702]), array([ 1.88744924]), array([ 1.88941972]), array([ 1.89731895]), array([ 1.86731642]), array([ 1.85917845]), array([ 1.88694816]), array([ 1.86731642]), array([ 1.83483222]), array([ 1.87753326]), array([ 1.86512157]), array([ 1.83018392]), array([ 1.83699189]), array([ 1.87360188]), array([ 1.89473133]), array([ 1.85545629]), array([ 1.88537905]), array([ 1.85009649]), array([ 1.88862199]), array([ 1.8683479]), array([ 2.02744004]), array([ 2.00456249]), array([ 2.02766367]), array([ 1.9548998]), array([ 2.00622327]), array([ 1.98142737]), array([ 2.00671688]), array([ 1.91551371]), array([ 2.01221972]), array([ 1.94451275]), array([ 1.92145721]), array([ 1.97908424]), array([ 1.97414725]), array([ 1.99910758]), array([ 1.95254917]), array([ 2.01075543]), array([ 1.97794635]), array([ 1.97572494]), array([ 1.98850207]), array([ 1.95992509]), array([ 1.99417905]), array([ 1.98002569]), array([ 2.00510287]), array([ 2.00034746]), array([ 1.99855476]), array([ 2.00694592]), array([ 2.02080944]), array([ 2.02163009]), array([ 1.98956736]), array([ 1.95331887]), array([ 1.95237017]), array([ 1.95050119]), array([ 1.96753356]), array([ 2.0022254]), array([ 1.97141402]), array([ 1.99342046]), array([ 2.01731061]), array([ 1.99225186]), array([ 1.96875714]), array([ 1.95709784]), array([ 1.97119345]), array([ 1.99744495]), array([ 1.96944076]), array([ 1.91818444]), array([ 1.96855571]), array([ 1.97611157]), array([ 1.97392977]), array([ 1.99251823]), array([ 1.91266871]), array([ 1.96998456]), array([ 2.02828729]), array([ 1.99266731]), array([ 2.04828931]), array([ 2.02283809]), array([ 2.02952984]), array([ 2.07386032]), array([ 1.94623197]), array([ 2.06331205]), array([ 2.03434414]), array([ 2.05624237]), array([ 2.01719007]), array([ 2.01541727]), array([ 2.03181852]), array([ 1.98352192]), array([ 1.98770135]), array([ 2.01593693]), array([ 2.02695469]), array([ 2.08336115]), array([ 2.07627131]), array([ 1.99562779]), array([ 2.03869465]), array([ 1.98092336]), array([ 2.07715026]), array([ 2.00371742]), array([ 2.03650416]), array([ 2.05751265]), array([ 1.99919007]), array([ 2.00082716]), array([ 2.02132133]), array([ 2.05358306]), array([ 2.05986123]), array([ 2.08387338]), array([ 2.0202029]), array([ 2.01309788]), array([ 2.01869153]), array([ 2.06469906]), array([ 2.02116093]), array([ 2.02517617]), array([ 1.99519727]), array([ 2.03312546]), array([ 2.02916945]), array([ 2.02401748]), array([ 1.99266731]), array([ 2.04049205]), array([ 2.03228781]), array([ 2.01994102]), array([ 2.00305587]), array([ 2.01767501]), array([ 2.01466738]), array([ 2.])] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "#x, y = shuffle(x, y)\n",
    "\n",
    "\n",
    "#xtest = x[100:]\n",
    "#ytest = y[100:]\n",
    "#x = x[:100]\n",
    "#y = y[:100]\n",
    "\n",
    "nt = network([4, 1], 0.05, 1.0, ['sigmoid', 'x'], \"square\", 'reg')\n",
    "nt.fit(x, y)\n",
    "ypred = nt.predict(x)\n",
    "print ypred, y\n",
    "#print np.sum((ytest - ypred) ** 2.0) / len(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = misc.imread('data/big_alphabet_29x29/mutant-0-0-0.bmp', flatten='grey')\n",
    "alphabet_size = 25\n",
    "im_size = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "x_test = []\n",
    "for letter in range(alphabet_size):\n",
    "    for i in range(8):\n",
    "        path = \"data/big_alphabet_29x29/mutant-\" + str(letter) + \"-\" + str(i) + \"-0.bmp\"\n",
    "        im = misc.imread(path, flatten='grey')\n",
    "        x.append(im.reshape(im_size * im_size))\n",
    "        y.append(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for letter in range(alphabet_size):\n",
    "    path = \"data/big_alphabet_29x29/class-\" + str(letter) + \".bmp\"\n",
    "    im = misc.imread(path, flatten='grey')\n",
    "    x_test.append(im.reshape(im_size * im_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 15,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 15,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 22,\n",
       " 24,\n",
       " 24]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt = network([1000, 26], 0.1, 1.0, ['sigmoid', 'sigmoid'], \"logistic\", 'class')\n",
    "nt.fit(x, y)\n",
    "nt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
