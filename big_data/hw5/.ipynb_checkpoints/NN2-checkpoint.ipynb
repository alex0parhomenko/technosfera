{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "import theano.tensor as th\n",
    "from scipy import misc\n",
    "import copy\n",
    "from numpy.random import uniform\n",
    "from numpy.random import normal\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_classification\n",
    "from math import copysign\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self, layers_list, learning_rate, alpha, activation_functions, cost_func, mode, \\\n",
    "                 cou_iter, early_stop, regularization, reg_param, batch_size):\n",
    "        self.layers_count = len(layers_list)\n",
    "        self.weight_list = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers_list = layers_list\n",
    "        self.alpha = alpha\n",
    "        self.cost_func = cost_func\n",
    "        self.activation_functions = activation_functions\n",
    "        self.mode = mode\n",
    "        self.batch_size = batch_size\n",
    "        self.cou_iter = cou_iter\n",
    "        self.early_stop = early_stop\n",
    "        self.regularization = regularization\n",
    "        self.reg_param = reg_param\n",
    "        for i in range(1, self.layers_count):\n",
    "            m = np.asarray(normal(0, 0.15, (self.layers_list[i - 1] + 1, self.layers_list[i])))\n",
    "            self.weight_list.append(m)\n",
    "            \n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        one = np.ones(len(x))\n",
    "        val = one / (one + np.exp(-x * self.alpha))\n",
    "        for i in range(len(val)):\n",
    "            if (val[i] == 0):\n",
    "                val[i] = 0.00001\n",
    "            elif (val[i] == 1):\n",
    "                val[i] = 0.99999\n",
    "        return one / (one + np.exp(-x * self.alpha))\n",
    "    \n",
    "    def der_sigmoid(self, x):\n",
    "        one = np.ones(len(x))\n",
    "        return (one - self.sigmoid(x)) * self.sigmoid(x) * self.alpha\n",
    "    \n",
    "    def x(self, x):\n",
    "        return x\n",
    "    \n",
    "    def der_x(self, x):\n",
    "        return np.ones(len(x))\n",
    "    \n",
    "    def hyp_tg(self, x):\n",
    "        return (np.exp(self.alpha * x) - np.exp(-self.alpha * x)) / (np.exp(self.alpha * x) + np.exp(-self.alpha * x))\n",
    "    \n",
    "    def der_hyp_tg(self, x):\n",
    "        return self.alpha * (1 - (self.hyp_tg(x)) ** 2)\n",
    "    \n",
    "    def logistic_cost(self, y_true, y_pred):\n",
    "        val = 0\n",
    "        if (self.mode == 'class'):\n",
    "            z = np.zeros(len(y_pred))\n",
    "            z[y_true] = 1\n",
    "            one = np.ones(len(y_pred))\n",
    "            y_true = z.copy()\n",
    "            val = -np.sum(y_true * np.log(y_pred) + (one - y_true) * np.log(one - y_pred))\n",
    "        elif (self.mode == 'reg'):\n",
    "            val = -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "        return val\n",
    "    \n",
    "    def der_logistic_cost(self, y_true, y_pred):\n",
    "        val = 0\n",
    "        if (self.mode == 'class'):\n",
    "            z = np.zeros(len(y_pred))\n",
    "            z[y_true] = 1\n",
    "            one = np.ones(len(y_pred))\n",
    "            y_true = z\n",
    "            val = ((one*1.0 - y_true*1.0) / (one - y_pred*1.0) - (y_true*1.0 / y_pred))\n",
    "        elif (self.mode == 'reg'):\n",
    "            val = ((1.0 - y_true) / (1.0 - y_pred) - y_true / y_pred)\n",
    "        return val\n",
    "    \n",
    "    def square_cost(self, y_true, y_pred):\n",
    "        return  0.5*((y_true - y_pred) ** 2.0)\n",
    "    \n",
    "    def der_square_cost(self, y_true, y_pred):\n",
    "        return (y_pred - y_true)\n",
    "    \n",
    "    def add_first_layer(self, x_shape):\n",
    "        self.weight_list.insert(0, np.asarray(normal(0, 0.15, (x_shape, self.layers_list[0]))))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = np.asarray(x)\n",
    "        x = np.insert(x, 0, [-1], axis = 1)\n",
    "        ans = []\n",
    "        for s_num, sample in enumerate(x):\n",
    "            v = sample\n",
    "            for num, layer in enumerate(self.weight_list):\n",
    "                v = np.dot(layer.T, v)\n",
    "                if (self.activation_functions[num] == 'sigmoid'):\n",
    "                    v = self.sigmoid(v)\n",
    "                elif (self.activation_functions[num] == 'hyp_tg'):\n",
    "                    v = self.hyp_tg(v)\n",
    "                elif (self.activation_functions[num] == 'x'):\n",
    "                    v = self.x(v)\n",
    "                if (num != self.layers_count - 1):\n",
    "                    v = np.insert(v, 0, [-1])\n",
    "            if (self.mode == 'class'):\n",
    "                ans.append(np.argmax(v))\n",
    "            elif (self.mode == 'reg'):\n",
    "                ans.append(v)\n",
    "        return ans\n",
    "    \n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        y = np.asarray(y)\n",
    "        x = np.insert(np.asarray(x), 0, -1, axis = 1)\n",
    "        self.add_first_layer(x.shape[1])\n",
    "        k = 0\n",
    "        total_err = np.inf\n",
    "        x_size = len(x)\n",
    "        while (k < self.cou_iter and (total_err / x_size) > self.early_stop):\n",
    "            print k, total_err / len(x)\n",
    "            total_err = 0.0\n",
    "            x, y = shuffle(x, y)\n",
    "            for s_num, sample in enumerate(x):\n",
    "                neuron_sum = []\n",
    "                neuron_out = []\n",
    "                neuron_out.append(np.asarray(sample, dtype = np.float))\n",
    "                v = sample\n",
    "                for num, layer in enumerate(self.weight_list):\n",
    "                    v = np.dot(layer.T, v)\n",
    "                    neuron_sum.append(v)\n",
    "                    if (self.activation_functions[num] == 'sigmoid'):\n",
    "                        v = self.sigmoid(v)\n",
    "                    elif (self.activation_functions[num] == 'hyp_tg'):\n",
    "                        v = self.hyp_tg(v)\n",
    "                    elif(self.activation_functions[num] == 'x'):\n",
    "                        v = self.x(v) \n",
    "                    if (num != self.layers_count - 1):\n",
    "                        v = np.insert(v, 0, [-1])\n",
    "                    neuron_out.append(v)\n",
    "\n",
    "                if (self.cost_func == \"logistic\"):\n",
    "                    total_err += self.logistic_cost(y[s_num], v)\n",
    "                elif (self.cost_func == \"square\"):\n",
    "                    total_err += self.square_cost(y[s_num], v)\n",
    "                    \n",
    "                if (neuron_out[-1].shape[0] == 1):\n",
    "                    neuron_out[-1] = neuron_out[-1][0]\n",
    "\n",
    "                if (self.cost_func == \"logistic\" and self.activation_functions[-1] == \"sigmoid\"):\n",
    "                    der_neuron = [(self.der_logistic_cost(y[s_num], neuron_out[-1]) * self.der_sigmoid(neuron_sum[-1]))]\n",
    "                elif (self.cost_func == \"logistic\" and self.activation_functions[-1] == \"hyp_tg\"):\n",
    "                    der_neuron = [(self.der_logistic_cost(y[s_num], neuron_out[-1]) * self.der_hyp_tg(neuron_sum[-1]))]\n",
    "                elif (self.cost_func == 'logistic' and self.activation_functions[-1] == \"x\"):\n",
    "                    der_neuron = [(self.der_logistic_cost(y[s_num], neuron_out[-1]) * self.der_x(neuron_sum[-1]))]\n",
    "                #elif(self.cost_func == \"square\" and self.activation_functions[-1] == \"sigmoid\"):\n",
    "                #    der_neuron = [(self.der_square_cost(y[s_num], neuron_out[-1]) * self.der_sigmoid(neuron_sum[-1]))]\n",
    "                #elif (self.cost_func == \"square\" and self.activation_functions[-1] == \"hyp_tg\"):\n",
    "                #    der_neuron = [(self.der_square_cost(y[s_num], neuron_out[-1]) * self.der_hyp_tg(neuron_sum[-1]))]\n",
    "                elif (self.cost_func == 'square' and self.activation_functions[-1] == \"x\"):\n",
    "                    der_neuron = [(self.der_square_cost(y[s_num], neuron_out[-1]) * self.der_x(neuron_sum[-1]))]\n",
    "                \n",
    "                num = 1\n",
    "                for layer in reversed(self.weight_list[1:]):\n",
    "                    if (self.activation_functions[self.layers_count - num - 1] == 'sigmoid'):\n",
    "                        der_neuron.insert(0, np.dot(layer[1:], der_neuron[0]) * self.der_sigmoid(neuron_sum[len(neuron_sum) - num - 1]))\n",
    "                    elif (self.activation_functions[self.layers_count - num - 1] == 'hyp_tg'):\n",
    "                        der_neuron.insert(0, np.dot(layer[1:], der_neuron[0]) * self.der_hyp_tg(neuron_sum[len(neuron_sum) - num - 1]))\n",
    "                    elif (self.activation_functions[self.layers_count - num - 1] == 'x'):\n",
    "                        der_neuron.insert(0, np.dot(layer[1:], der_neuron[0]) * self.der_x(neuron_sum[len(neuron_sum) - num - 1]))\n",
    "                    num += 1\n",
    "\n",
    "                for layer_num in range(self.layers_count):\n",
    "                    if (self.regularization == 'l1'):\n",
    "                        self.weight_list[self.layers_count - layer_num - 1] -= (self.learning_rate * \\\n",
    "                        np.dot(neuron_out[len(neuron_out) - layer_num - 2].T.reshape(-1, 1), der_neuron[len(der_neuron) - layer_num - 1].reshape(1, -1)) +\\\n",
    "                        self.reg_param * np.sign(self.weight_list[self.layers_count - layer_num - 1]))\n",
    "                    elif (self.regularization == 'l2'):\n",
    "                        self.weight_list[self.layers_count - layer_num - 1] -= (self.learning_rate * \\\n",
    "                        np.dot(neuron_out[len(neuron_out) - layer_num - 2].T.reshape(-1, 1), der_neuron[len(der_neuron) - layer_num - 1].reshape(1, -1)) +\\\n",
    "                        self.reg_param * self.weight_list[self.layers_count - layer_num - 1])\n",
    "                \n",
    "            k += 1\n",
    "\n",
    "            \n",
    "            \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 inf\n",
      "1 1.95702077974\n",
      "2 1.8502977456\n",
      "3 1.64231446045\n",
      "4 1.35483462012\n",
      "5 1.17016997601\n",
      "6 1.06944915984\n",
      "7 1.01256850445\n",
      "8 0.991419063763\n",
      "9 0.951496789614\n",
      "10 0.944787312325\n",
      "11 0.912723261623\n",
      "12 0.900291129918\n",
      "13 0.858676313468\n",
      "14 0.859748492182\n",
      "15 0.828222201933\n",
      "16 0.813894557096\n",
      "17 0.793053377703\n",
      "18 0.749793930714\n",
      "19 0.715163983958\n",
      "20 0.663819470042\n",
      "21 0.639873875553\n",
      "22 0.681074250077\n",
      "23 0.577762579758\n",
      "24 0.62680603369\n",
      "25 0.543553970065\n",
      "26 0.540371118647\n",
      "27 0.585805296481\n",
      "28 0.51759451564\n",
      "29 0.526848106402\n",
      "30 0.494043430206\n",
      "31 0.490791252456\n",
      "32 0.497564258519\n",
      "33 0.448646820876\n",
      "34 0.459715749229\n",
      "35 0.475461785909\n",
      "36 0.431817660657\n",
      "37 0.446850483883\n",
      "38 0.499651464386\n",
      "39 0.42365224046\n",
      "40 0.492762003774\n",
      "41 0.330922026811\n",
      "42 0.446006873848\n",
      "43 0.430481576834\n",
      "44 0.385879346101\n",
      "45 0.403416806144\n",
      "46 0.345628146415\n",
      "47 0.367719214491\n",
      "48 0.324810633659\n",
      "49 0.392820301072\n",
      "50 0.430649036295\n",
      "51 0.455071564366\n",
      "52 0.365080237777\n",
      "53 0.366712654\n",
      "54 0.351826715111\n",
      "55 0.366310804779\n",
      "56 0.372704382971\n",
      "57 0.366294289277\n",
      "58 0.321354517491\n",
      "59 0.303801182389\n",
      "60 0.308410030575\n",
      "61 0.412709716718\n",
      "62 0.36118762228\n",
      "63 0.371002637795\n",
      "64 0.38612561359\n",
      "65 0.298131392611\n",
      "66 0.261731807161\n",
      "67 0.318589779475\n",
      "68 0.341697371675\n",
      "69 0.246997169701\n",
      "70 0.451158604951\n",
      "71 0.447962065939\n",
      "72 0.250612778205\n",
      "73 0.266760746046\n",
      "74 0.340774449397\n",
      "75 0.301683224875\n",
      "76 0.326093779276\n",
      "77 0.299620936169\n",
      "78 0.290660645032\n",
      "79 0.336415168108\n",
      "[2, 2, 1, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 1, 0, 2, 0, 2, 1, 2, 1, 0, 1, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 0, 1, 0, 2, 1, 2] [1 2 1 1 0 0 1 0 0 2 1 0 0 0 1 0 2 0 2 1 2 1 0 1 0 1 0 1 2 0 1 2 0 2 1 1 2\n",
      " 1 1 2 1 1 1 1 0 1 0 2 1 2]\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "x, y = shuffle(x, y)\n",
    "\n",
    "xtest = x[100:]\n",
    "ytest = y[100:]\n",
    "x = x[:100]\n",
    "y = y[:100]\n",
    "\n",
    "nt = network([4, 3], 0.05, 1.0, ['sigmoid', 'sigmoid'], \"logistic\", 'class', 80, early_stop=0.0, \\\n",
    "             regularization='l2', reg_param = 0.0001)\n",
    "nt.fit(x, y)\n",
    "ypred = nt.predict(xtest)\n",
    "print ypred, ytest\n",
    "print accuracy_score(ytest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 inf\n",
      "1 1.92145529992\n",
      "2 1.81168815265\n",
      "3 1.72375462834\n",
      "4 1.68614000415\n",
      "5 1.64731402645\n",
      "6 1.6708523839\n",
      "7 1.60123567287\n",
      "8 1.59328521091\n",
      "9 1.53129508097\n",
      "10 1.5737240934\n",
      "11 1.57158593011\n",
      "12 1.56490795902\n",
      "13 1.57202521308\n",
      "14 1.55676504571\n",
      "15 1.55648045632\n",
      "16 1.5539984295\n",
      "17 1.53274492044\n",
      "18 1.48680449782\n",
      "19 1.5714621444\n",
      "20 1.52672902506\n",
      "21 1.51611052873\n",
      "22 1.53867607624\n",
      "23 1.53428500727\n",
      "24 1.53639165945\n",
      "25 1.51738589156\n",
      "26 1.53705665368\n",
      "27 1.57563606697\n",
      "28 1.54895920731\n",
      "29 1.57481665791\n",
      "30 1.54717906365\n",
      "31 1.53923310733\n",
      "32 1.53634314475\n",
      "33 1.51338633908\n",
      "34 1.53865759821\n",
      "35 1.52604302711\n",
      "36 1.50671125132\n",
      "37 1.51454112846\n",
      "38 1.53907060538\n",
      "39 1.53379944575\n",
      "40 1.5545107563\n",
      "41 1.55847176115\n",
      "42 1.54246939833\n",
      "43 1.54140731388\n",
      "44 1.50902548136\n",
      "45 1.50053150963\n",
      "46 1.52303802434\n",
      "47 1.53624328595\n",
      "48 1.5616741874\n",
      "49 1.52246462643\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "x, y = make_classification(n_samples=500, n_features=20, n_informative=10, n_classes=4)\n",
    "xtest = x[450:]\n",
    "ytest = y[450:]\n",
    "x = x[:450]\n",
    "y = y[:450]\n",
    "nt = network([35, 4], 0.1, 1.0, ['sigmoid', 'sigmoid'], \"logistic\", 'class', 50, early_stop=0.0, \\\n",
    "             regularization='l2', reg_param = 0.001)\n",
    "nt.fit(x, y)\n",
    "\n",
    "ypred = nt.predict(xtest)\n",
    "print accuracy_score(ypred, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = misc.imread('data/big_alphabet_29x29/mutant-0-0-0.bmp', flatten='grey')\n",
    "alphabet_size = 26\n",
    "im_size = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "x_test = []\n",
    "for letter in range(alphabet_size):\n",
    "    for i in range(9):\n",
    "        path = \"data/big_alphabet_29x29/mutant-\" + str(letter) + \"-\" + str(i) + \"-0.bmp\"\n",
    "        im = misc.imread(path, flatten='grey')\n",
    "        x.append(im.reshape(im_size * im_size))\n",
    "        x[-1] /= 255\n",
    "        y.append(letter)\n",
    "for letter in range(alphabet_size):\n",
    "    path = \"data/big_alphabet_29x29/class-\" + str(letter) + \".bmp\"\n",
    "    im = misc.imread(path, flatten='grey')\n",
    "    x_test.append(im.reshape(im_size * im_size))\n",
    "    x_test[-1] /= 255\n",
    "ytest = np.arange(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 inf\n",
      "1 4.67422143208\n",
      "2 4.3179979001\n",
      "3 4.01570014272\n",
      "4 3.67543148333\n",
      "5 3.26670565283\n",
      "6 2.95915974769\n",
      "7 2.66005716986\n",
      "8 2.37449560188\n",
      "9 2.13987030762\n",
      "10 1.91283366665\n",
      "11 1.74171563305\n",
      "12 1.57693752938\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "nt = network(layers_list=[43, 26], learning_rate=0.03, alpha=1.0, \\\n",
    "             activation_functions=['sigmoid', 'sigmoid'], cost_func=\"logistic\", \\\n",
    "             mode='class', cou_iter=100, early_stop=1.5, regularization = 'l2', reg_param = 0.0001)\n",
    "nt.fit(x, y)\n",
    "\n",
    "ypred = nt.predict(x_test)\n",
    "print ypred\n",
    "print accuracy_score(ytest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
